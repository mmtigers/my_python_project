#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Production Grade Batch Downloader (v2.2.0 Universal Support)
-------------------------------------------------
Features:
- Multi-List Support: Automatically processes all files in 'list/' directory.
- Smart Organization: Creates subfolders based on list filenames.
- Atomic File Writes & Robust Error Handling.
- Download History Management.
- Discord Notifications.
- Schedule: 02:00 - 06:00.
- Universal Support: Uses yt-dlp for ALL supported sites (not just YouTube).
- Specialized Scraping: Specific logic for 'tktube'.
"""

import os
import sys
import time
import re
import shutil
import datetime
import logging
import signal
import requests
import glob
from collections import defaultdict
from abc import ABC, abstractmethod
from typing import List, Optional, Tuple, Any, Set, NamedTuple
from dataclasses import dataclass, field
from pathlib import Path

# External Libraries
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from tqdm import tqdm
import yt_dlp

# ==========================================
# 0. ç’°å¢ƒè¨­å®š & ãƒ­ã‚®ãƒ³ã‚°
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger("Downloader")

FORCE_MODE = "--force" in sys.argv

CURRENT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = CURRENT_DIR
for _ in range(3):
    if (PROJECT_ROOT / "services").exists():
        break
    PROJECT_ROOT = PROJECT_ROOT.parent
else:
    PROJECT_ROOT = Path("/home/masahiro/develop/MY_HOME_SYSTEM")

if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

try:
    from services.notification_service import _send_discord_webhook
except ImportError:
    logger.warning("âš ï¸ Notification Service not found. Discord notification disabled.")
    def _send_discord_webhook(messages, image_data=None, channel="notify"):
        pass

# ==========================================
# 1. ã‚³ãƒ³ãƒ•ã‚£ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
# ==========================================
@dataclass(frozen=True)
class AppConfig:
    RESTRICT_TIME: bool = not FORCE_MODE
    START_HOUR: int = 2
    END_HOUR: int = 6
    SHORT_SLEEP_SECONDS: int = 5
    MIN_FREE_SPACE_GB: int = 50
    
    # ã€è¿½åŠ ã€‘æ©Ÿèƒ½ãƒ•ãƒ©ã‚°: ç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡å¯èƒ½ã«ã™ã‚‹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯False=ç„¡åŠ¹ã®ã¾ã¾ç¶­æŒ)
    ENABLE_YOUTUBE_DL: bool = os.getenv("ENABLE_YOUTUBE_DL", "false").lower() == "true"
    BASE_SAVE_DIR: Path = Path(os.getenv("VIDEO_SAVE_DIR", "/mnt/nas/ddd"))
    LIST_FILE_PATH: Path = CURRENT_DIR / "list.txt"
    LIST_DIR_PATH: Path = CURRENT_DIR / "list"
    HISTORY_FILE_PATH: Path = CURRENT_DIR / "history.txt"
    NAS_MOUNT_POINT: Path = Path("/mnt/nas")
    NAS_MARKER_FILE: str = ".mounted"
    
    REQUEST_TIMEOUT: int = 20
    MAX_RETRIES: int = 3
    
    # æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ (Specialized Scraping)
    URL_PATTERNS: List[Tuple[str, str]] = field(default_factory=lambda: [
        ('HD', r"video_alt_url\s*:\s*['\"]([^'\"]+)['\"]"),
        ('SD', r"video_url\s*:\s*['\"]([^'\"]+)['\"]"),
    ])
    
    SHOW_PROGRESS_BAR: bool = sys.stdout.isatty()

    @property
    def nas_marker_path(self) -> Path:
        return self.NAS_MOUNT_POINT / self.NAS_MARKER_FILE

CONFIG = AppConfig()

class DownloadTask(NamedTuple):
    url: str
    source_name: str

# ==========================================
# 2. ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ & ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==========================================
class DiscordNotifier:
    @staticmethod
    def send(text: str, is_error: bool = False) -> None:
        channel = 'error' if is_error else 'notify'
        message = {"type": "text", "text": text}
        try:
            _send_discord_webhook([message], channel=channel)
        except Exception as e:
            logger.error(f"âš ï¸ Discordé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")

class HistoryManager:
    @staticmethod
    def load_history() -> Set[str]:
        history = set()
        if CONFIG.HISTORY_FILE_PATH.exists():
            try:
                with open(CONFIG.HISTORY_FILE_PATH, "r", encoding="utf-8") as f:
                    history = {line.strip() for line in f if line.strip()}
            except Exception: pass
        return history

    @staticmethod
    def add_history(url: str) -> None:
        try:
            with open(CONFIG.HISTORY_FILE_PATH, "a", encoding="utf-8") as f:
                f.write(f"{url}\n")
        except Exception: pass

class NetworkManager:
    @staticmethod
    def create_session() -> requests.Session:
        session = requests.Session()
        retries = Retry(total=CONFIG.MAX_RETRIES, backoff_factor=2, status_forcelist=[500, 502, 503, 504])
        session.mount("http://", HTTPAdapter(max_retries=retries))
        session.mount("https://", HTTPAdapter(max_retries=retries))
        session.headers.update({'User-Agent': 'Mozilla/5.0 ... Chrome/120.0.0.0 Safari/537.36'})
        return session

class FileSystemManager:
    @staticmethod
    def sanitize_filename(filename: str) -> str:
        return re.sub(r'[\\/*?:"<>|]', '_', filename)

    @staticmethod
    def ensure_dir(path: Path) -> bool:
        try:
            path.mkdir(parents=True, exist_ok=True)
            return True
        except PermissionError:
            DiscordNotifier.send(f"âŒ æ¨©é™ã‚¨ãƒ©ãƒ¼: {path}", is_error=True)
            return False

    @staticmethod
    def check_disk_space(path: Path) -> bool:
        try:
            check_path = path
            while not check_path.exists():
                check_path = check_path.parent
                if check_path == check_path.parent: break
            total, used, free = shutil.disk_usage(check_path)
            if (free // (2**30)) < CONFIG.MIN_FREE_SPACE_GB:
                DiscordNotifier.send(f"âš ï¸ DISK FULL: æ®‹ã‚Š {free // (2**30)}GB", is_error=True)
                return False
            return True
        except Exception:
            return True

class SystemHealthChecker:
    @staticmethod
    def is_within_time_window() -> bool:
        if not CONFIG.RESTRICT_TIME: return True
        return CONFIG.START_HOUR <= datetime.datetime.now().hour < CONFIG.END_HOUR

    @staticmethod
    def verify_nas_mount() -> bool:
        if not CONFIG.NAS_MOUNT_POINT.exists() or not CONFIG.nas_marker_path.exists():
            DiscordNotifier.send("â›” CRITICAL: NASãƒã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼", is_error=True)
            return False
        return True
    
    @staticmethod
    def check_dependencies() -> None:
        if shutil.which("ffmpeg") is None:
            logger.warning("âš ï¸ ffmpeg not found.")

# ==========================================
# 3. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆ¦ç•¥ (Strategy Pattern)
# ==========================================
class DownloadStrategy(ABC):
    def __init__(self, save_base_dir: Path, session: requests.Session):
        self.save_base_dir = save_base_dir
        self.session = session

    @abstractmethod
    def download(self, task: DownloadTask) -> bool:
        pass

    def _determine_save_dir(self, source_name: str, category: str = "others") -> Optional[Path]:
        if source_name == "list":
            target_dir = self.save_base_dir / category
        else:
            target_dir = self.save_base_dir / category / source_name
        
        if not FileSystemManager.ensure_dir(target_dir): return None
        if not FileSystemManager.check_disk_space(target_dir): return None
        return target_dir

    def _should_skip(self, filepath: Path) -> bool:
        if filepath.exists() and filepath.stat().st_size > 0:
            logger.info(f"â­ï¸ Skip: {filepath.name}")
            return True
        return False

# â˜…å¤‰æ›´ç‚¹: YouTubeStrategy ã‚’ UniversalYtDlpStrategy ã«åç§°å¤‰æ›´ã—ã€æ±ç”¨çš„ã«åˆ©ç”¨
class UniversalYtDlpStrategy(DownloadStrategy):
    def download(self, task: DownloadTask) -> bool:
        logger.info(f"ğŸ¥ Universalå‡¦ç†: {task.url} (List: {task.source_name})")
        
        # YouTubeã®å ´åˆã¯ "youtube" ãƒ•ã‚©ãƒ«ãƒ€ã€ãã‚Œä»¥å¤–ã¯ "others" ãƒ•ã‚©ãƒ«ãƒ€ã«åˆ†é¡
        category = "youtube" if "youtube.com" in task.url or "youtu.be" in task.url else "others"
        
        target_dir = self._determine_save_dir(task.source_name, category)
        if not target_dir: return False

        ydl_opts = {
            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
            'outtmpl': f'{str(target_dir)}/%(title)s.%(ext)s',
            'merge_output_format': 'mp4',
            'quiet': True, 'no_warnings': True, 'nopart': False,
        }

        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(task.url, download=False)
                filename = Path(ydl.prepare_filename(info)).with_suffix('.mp4')
                
                if self._should_skip(filename): return True

                logger.info(f"ğŸ“¥ DLé–‹å§‹: {info.get('title')}")
                ydl.download([task.url])
                DiscordNotifier.send(f"âœ… å‹•ç”»ä¿å­˜å®Œäº†\nãƒ•ã‚¡ã‚¤ãƒ«: `{filename.name}`")
                return True
        except Exception as e:
            logger.error(f"âš ï¸ Universal DL ã‚¨ãƒ©ãƒ¼: {e}")
            return False

# â˜…å¤‰æ›´ç‚¹: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒå¿…è¦ãªç‰¹å®šã‚µã‚¤ãƒˆå°‚ç”¨
class ScrapingStrategy(DownloadStrategy):
    def download(self, task: DownloadTask) -> bool:
        category = "tktube"
        target_dir = self._determine_save_dir(task.source_name, category)
        if not target_dir: return False

        html = self._fetch_html(task.url)
        if not html: return False

        candidates = self._extract_video_urls(html)
        if not candidates:
            logger.warning("âš ï¸ å‹•ç”»ãƒªãƒ³ã‚¯ãªã—")
            return False

        filename = FileSystemManager.sanitize_filename(task.url.split('?')[0].rstrip('/').split('/')[-1] or f"vid_{int(time.time())}") + ".mp4"
        final_path = target_dir / filename

        if self._should_skip(final_path): return True
        return self._execute_atomic_download(candidates, final_path, task.url, target_dir)

    def _fetch_html(self, url: str) -> Optional[str]:
        try:
            self.session.headers['Referer'] = url
            res = self.session.get(url, timeout=CONFIG.REQUEST_TIMEOUT)
            return res.text
        except Exception: return None

    def _extract_video_urls(self, html: str) -> List[Tuple[str, str]]:
        urls = []
        for label, pattern in CONFIG.URL_PATTERNS:
            match = re.search(pattern, html)
            if match: urls.append((label, match.group(1).strip().rstrip('/')))
        return urls

    def _execute_atomic_download(self, candidates: List[Tuple[str, str]], final_path: Path, src_url: str, save_dir: Path) -> bool:
        temp_path = final_path.with_suffix('.tmp')
        self.session.headers['Referer'] = src_url
        
        for label, video_url in candidates:
            try:
                with self.session.get(video_url, stream=True, timeout=CONFIG.REQUEST_TIMEOUT) as res:
                    if res.status_code == 404: continue
                    total = int(res.headers.get('content-length', 0))
                    with open(temp_path, 'wb') as f, tqdm(total=total, unit='iB', unit_scale=True, disable=not CONFIG.SHOW_PROGRESS_BAR) as bar:
                        for chunk in res.iter_content(1024*1024):
                            size = f.write(chunk)
                            bar.update(size)
                    temp_path.rename(final_path)
                    DiscordNotifier.send(f"âœ… å‹•ç”»ä¿å­˜å®Œäº†\nãƒ•ã‚¡ã‚¤ãƒ«: `{final_path.name}`\nå ´æ‰€: `{save_dir.name}`")
                    return True
            except Exception:
                if temp_path.exists(): temp_path.unlink()
                continue
        return False

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
# ==========================================
class BatchDownloader:
    def __init__(self):
        self.session = NetworkManager.create_session()
        self._shutdown_requested = False
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        self.history = HistoryManager.load_history()

    def _signal_handler(self, signum: int, frame: Any) -> None:
        logger.info("ğŸ›‘ åœæ­¢ã‚·ã‚°ãƒŠãƒ«æ¤œçŸ¥")
        self._shutdown_requested = True

    def _get_strategy(self, url: str) -> Optional[DownloadStrategy]:
        # ã€ä¿®æ­£ã€‘ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã§ã¯ãªãã€è¨­å®šãƒ•ãƒ©ã‚°ã§åˆ¶å¾¡ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´
        if "youtube.com" in url or "youtu.be" in url:
            if not CONFIG.ENABLE_YOUTUBE_DL:
                logger.info(f"ğŸš« YouTubeæ©Ÿèƒ½ã¯è¨­å®šã«ã‚ˆã‚Šç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™: {url}")
                return None
            # æœ‰åŠ¹ãªå ´åˆã¯é€šå¸¸ã®ãƒ•ãƒ­ãƒ¼ã¸é€²ã‚€

        # æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯: tktubeãªã‚‰å°‚ç”¨ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ã€ãã‚Œä»¥å¤–ã¯Universal
        if "tktube" in url:
            return ScrapingStrategy(CONFIG.BASE_SAVE_DIR, self.session)
        else:
            # YouTubeä»¥å¤–ã®æ±ç”¨ã‚µã‚¤ãƒˆï¼ˆTwitter/X, Vimeoãªã©ï¼‰ã¯å¼•ãç¶šããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½
            return UniversalYtDlpStrategy(CONFIG.BASE_SAVE_DIR, self.session)

    def _collect_tasks(self) -> List[DownloadTask]:
        tasks = []
        
        if CONFIG.LIST_FILE_PATH.exists():
            with open(CONFIG.LIST_FILE_PATH, "r", encoding="utf-8") as f:
                for line in f:
                    url = line.strip()
                    if url and not url.startswith("#") and url not in self.history:
                        tasks.append(DownloadTask(url, "list"))
        
        if CONFIG.LIST_DIR_PATH.exists():
            for list_file in CONFIG.LIST_DIR_PATH.glob("*.txt"):
                source_name = list_file.stem
                try:
                    with open(list_file, "r", encoding="utf-8") as f:
                        for line in f:
                            url = line.strip()
                            if url and not url.startswith("#") and url not in self.history:
                                tasks.append(DownloadTask(url, source_name))
                except Exception as e:
                    logger.error(f"ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({list_file.name}): {e}")

        unique_tasks = {}
        for t in tasks:
            if t.url not in unique_tasks:
                unique_tasks[t.url] = t
        
        return list(unique_tasks.values())

    def _purge_skipped_tasks(self, skipped_tasks: List[DownloadTask]) -> None:
        """
        ã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ã¨ãªã£ãŸã‚¿ã‚¹ã‚¯ã‚’å…ƒãƒªã‚¹ãƒˆã‹ã‚‰ç‰©ç†å‰Šé™¤ã—ã€ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¸é€€é¿ã™ã‚‹ã€‚
        
        Args:
            skipped_tasks (List[DownloadTask]): ãƒ‘ãƒ¼ã‚¸å¯¾è±¡ã®ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ
        """
        if not skipped_tasks:
            return

        # 1. ã‚¿ã‚¹ã‚¯ã‚’ã‚½ãƒ¼ã‚¹(ãƒ•ã‚¡ã‚¤ãƒ«å)ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        tasks_by_source = defaultdict(set)
        for task in skipped_tasks:
            tasks_by_source[task.source_name].add(task.url)

        deleted_count = 0
        archive_path = CONFIG.BASE_SAVE_DIR / "archived_tasks.txt"

        # 2. ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¸ã®è¿½è¨˜ï¼ˆSSOTã‹ã‚‰ãƒ‘ãƒ¼ã‚¸ã•ã‚ŒãŸè¨¼è·¡ã‚’æ®‹ã™ï¼‰
        try:
            with open(archive_path, "a", encoding="utf-8") as af:
                af.write(f"\n# Archived on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                for task in skipped_tasks:
                    af.write(f"{task.url}\n")
        except Exception as e:
            logger.error(f"âš ï¸ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¤±æ•—æ™‚ã¯å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã‚‚ä¸­æ–­ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ãƒˆé˜²æ­¢ï¼‰

        # 3. å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ç‰©ç†å‰Šé™¤ï¼ˆã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ä¸Šæ›¸ãï¼‰
        for source_name, urls_to_remove in tasks_by_source.items():
            if source_name == "list":
                file_path = CONFIG.LIST_FILE_PATH
            else:
                file_path = CONFIG.LIST_DIR_PATH / f"{source_name}.txt"

            if not file_path.exists():
                continue

            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    lines = f.readlines()

                # ãƒ‘ãƒ¼ã‚¸å¯¾è±¡å¤–ã®è¡Œã ã‘ã‚’æ®‹ã™
                retained_lines = []
                for line in lines:
                    url = line.strip()
                    if url in urls_to_remove:
                        deleted_count += 1
                        logger.debug(f"ğŸ—‘ï¸ ãƒ‘ãƒ¼ã‚¸å®Ÿè¡Œ: {url} (from {source_name})")
                    else:
                        retained_lines.append(line)

                # ã‚¢ãƒˆãƒŸãƒƒã‚¯ãªä¸Šæ›¸ãæ›´æ–°
                temp_path = file_path.with_suffix('.tmp')
                with open(temp_path, "w", encoding="utf-8") as f:
                    f.writelines(retained_lines)
                temp_path.replace(file_path)

            except Exception as e:
                logger.error(f"âš ï¸ ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«({file_path.name})ã®ãƒ‘ãƒ¼ã‚¸å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        logger.info(f"ğŸ§¹ æœŸé™åˆ‡ã‚Œï¼ˆç„¡åŠ¹ï¼‰ã®ã‚¿ã‚¹ã‚¯ {deleted_count} ä»¶ã‚’ãƒ‘ãƒ¼ã‚¸ã—ã¾ã—ãŸã€‚")


    def run(self) -> None:
        SystemHealthChecker.check_dependencies()
        
        if not SystemHealthChecker.is_within_time_window():
            if FORCE_MODE: 
                logger.debug("âš ï¸ FORCEãƒ¢ãƒ¼ãƒ‰: æ™‚é–“åˆ¶é™ç„¡è¦–")
            else:
                logger.debug(f"ğŸ•’ æŒ‡å®šæ™‚é–“å¤–ï¼ˆ{CONFIG.START_HOUR}:00 - {CONFIG.END_HOUR}:00ï¼‰ã®ãŸã‚çµ‚äº†")
                return

        if not SystemHealthChecker.verify_nas_mount(): 
            return

        tasks = self._collect_tasks()
        if not tasks:
            logger.debug("å‡¦ç†å¯¾è±¡ã®URLãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # YouTubeç„¡åŠ¹æ™‚ã¯ã‚¿ã‚¹ã‚¯ã‚’é™¤å¤–ã—ã€ãƒ‘ãƒ¼ã‚¸å‡¦ç†ã¸å›ã™
        skipped_tasks = []
        if not CONFIG.ENABLE_YOUTUBE_DL:
            valid_tasks = []
            for t in tasks:
                if "youtube.com" in t.url or "youtu.be" in t.url:
                    skipped_tasks.append(t)
                else:
                    valid_tasks.append(t)
            
            if skipped_tasks:
                logger.info(f"ğŸš« YouTubeæ©Ÿèƒ½ãŒç„¡åŠ¹ãªãŸã‚ã€{len(skipped_tasks)} ä»¶ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ãŠã‚ˆã³ãƒ‘ãƒ¼ã‚¸ã—ã¾ã™ã€‚")
                self._purge_skipped_tasks(skipped_tasks)
            
            tasks = valid_tasks

        # ãƒ‘ãƒ¼ã‚¸å¾Œã€ã‚¿ã‚¹ã‚¯ãŒ0ã«ãªã£ãŸå ´åˆã¯çµ‚äº†
        if not tasks:
            logger.debug("ãƒ‘ãƒ¼ã‚¸å‡¦ç†ã®çµæœã€å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ãŒãªããªã‚Šã¾ã—ãŸã€‚")
            return

        logger.info("="*60)
        logger.info("   ğŸš€ Smart Pipeline Downloader (v2.2.0)")
        logger.info(f"   Schedule: {CONFIG.START_HOUR}:00 - {CONFIG.END_HOUR}:00")
        logger.info(f"   Tasks: {len(tasks)}")
        logger.info("="*60)

        for i, task in enumerate(tasks):
            if self._shutdown_requested: break
            if not SystemHealthChecker.is_within_time_window() and not FORCE_MODE:
                logger.info("â° çµ‚äº†æ™‚åˆ»ã«ã‚ˆã‚Šä¸­æ–­")
                break

            logger.info(f"\n[{i+1}/{len(tasks)}] é–‹å§‹: {task.url}")
            
            try:
                strategy = self._get_strategy(task.url)
                
                # ã€è¿½åŠ ã€‘YouTubeç­‰ã®ã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ï¼ˆNoneï¼‰ã ã£ãŸå ´åˆã¯æ¬¡ã¸
                if strategy is None:
                    continue

                if strategy.download(task):
                    HistoryManager.add_history(task.url)
            except Exception as e:
                logger.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

            if i < len(tasks) - 1:
                if not self._shutdown_requested:
                    time.sleep(CONFIG.SHORT_SLEEP_SECONDS)

        logger.info("ğŸ‰ å…¨å‡¦ç†çµ‚äº†")

if __name__ == "__main__":
    BatchDownloader().run()