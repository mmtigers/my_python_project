#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
YouTube URL Extractor (v3.0.0 Auto-Subscription)
-----------------------------------------------
Features:
- Subscription Mode: Auto-crawl channels listed in 'subscriptions.txt'.
- Channel Crawling: Extracts /videos & /playlists automatically.
- Organized Output: Saves to 'list/Channel_Playlist.txt'.
- High Performance Metadata Extraction (extract_flat).
"""

import sys
import argparse
import logging
import re
import time
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Optional, Set, Iterator
import yt_dlp

# ==========================================
# 0. ç’°å¢ƒè¨­å®š & ãƒ­ã‚®ãƒ³ã‚°
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("UrlExtractor")

CURRENT_DIR = Path(__file__).resolve().parent

# ==========================================
# 1. ã‚³ãƒ³ãƒ•ã‚£ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
# ==========================================
@dataclass(frozen=True)
class AppConfig:
    OUTPUT_DIR: Path = CURRENT_DIR
    SUB_DIR_NAME: str = "list"
    SUBSCRIPTION_FILE: str = "subscriptions.txt"
    
    YDL_OPTS: dict = field(default_factory=lambda: {
        'extract_flat': True,
        'quiet': True,
        'ignoreerrors': True,
        'no_warnings': True,
    })

CONFIG = AppConfig()

@dataclass
class ExtractionResult:
    title: str
    urls: List[str]
    source_url: str
    channel_name: str = "unknown_channel"
    is_playlist: bool = False

# ==========================================
# 2. ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ (Extractor)
# ==========================================
class YouTubeExtractor:
    
    @staticmethod
    def _normalize_url(entry: dict) -> Optional[str]:
        url = entry.get('url') or entry.get('webpage_url')
        video_id = entry.get('id')
        
        if video_id:
            return f"https://www.youtube.com/watch?v={video_id}"
        
        if url and ("youtube.com" in url or "youtu.be" in url):
            return url
        return None

    def _is_channel_url(self, url: str) -> bool:
        clean_url = url.split('?')[0].rstrip('/')
        return bool(re.search(r"youtube\.com/(@[\w\-\.]+|channel/[\w\-]+|c/[\w\-]+|user/[\w\-]+)$", clean_url))

    def _extract_single_list(self, target_url: str, force_title: str = "") -> Optional[ExtractionResult]:
        logger.info(f"ğŸ” è§£æä¸­...: {target_url}")
        
        results: Set[str] = set()
        list_title = force_title or "unknown_list"
        channel_name = "unknown_channel"

        try:
            with yt_dlp.YoutubeDL(CONFIG.YDL_OPTS) as ydl:
                info = ydl.extract_info(target_url, download=False)
                if not info: return None

                channel_name = info.get('channel') or info.get('uploader') or "unknown_channel"
                if not force_title:
                    list_title = info.get('title') or "extracted_urls"
                
                entries = info.get('entries')
                if entries:
                    logger.info(f"   â†³ ãƒªã‚¹ãƒˆå–å¾—ä¸­: '{list_title}' (by {channel_name})")
                    for entry in entries:
                        if not entry: continue
                        url = self._normalize_url(entry)
                        if url: results.add(url)
                else:
                    url = self._normalize_url(info)
                    if url: results.add(url)

        except Exception as e:
            logger.warning(f"âš ï¸ æŠ½å‡ºã‚¹ã‚­ãƒƒãƒ— ({target_url}): {e}")
            return None

        sorted_urls = sorted(list(results))
        if not sorted_urls:
            return None

        return ExtractionResult(
            title=list_title,
            urls=sorted_urls,
            source_url=target_url,
            channel_name=channel_name
        )

    def extract_iter(self, target_url: str) -> Iterator[ExtractionResult]:
        if self._is_channel_url(target_url):
            logger.info("â„¹ï¸ ãƒãƒ£ãƒ³ãƒãƒ«URLã‚’æ¤œå‡ºã€‚è©³ç´°ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            base_url = target_url.split('?')[0].rstrip('/')

            # Phase 1: All Videos
            video_result = self._extract_single_list(f"{base_url}/videos")
            if video_result:
                video_result.title += " - All Videos"
                yield video_result

            # Phase 2: Playlists
            try:
                with yt_dlp.YoutubeDL(CONFIG.YDL_OPTS) as ydl:
                    pl_tab = ydl.extract_info(f"{base_url}/playlists", download=False)
                    if pl_tab and 'entries' in pl_tab:
                        playlists = list(pl_tab['entries'])
                        logger.info(f"ğŸ“‚ {len(playlists)} å€‹ã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                        for pl in playlists:
                            if not pl: continue
                            pl_url = pl.get('url')
                            pl_title = pl.get('title', 'Unknown Playlist')
                            if pl_url:
                                res = self._extract_single_list(pl_url, force_title=pl_title)
                                if res:
                                    res.is_playlist = True
                                    yield res
            except Exception as e:
                logger.error(f"âŒ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆä¸€è¦§å–å¾—å¤±æ•—: {e}")
        else:
            res = self._extract_single_list(target_url)
            if res: yield res

# ==========================================
# 3. ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç† & ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³
# ==========================================
class FileManager:
    
    @staticmethod
    def _sanitize_filename(filename: str) -> str:
        safe = re.sub(r'[\\/*?:"<>|]', '_', filename).strip()
        return safe[:200].strip('. ')

    def save(self, result: ExtractionResult, output_base_dir: Path) -> bool:
        target_dir = output_base_dir / CONFIG.SUB_DIR_NAME
        target_dir.mkdir(parents=True, exist_ok=True)

        safe_channel = self._sanitize_filename(result.channel_name)
        safe_title = self._sanitize_filename(result.title)
        
        filename = f"{safe_title}.txt" if safe_channel == "unknown_channel" else f"{safe_channel}_{safe_title}.txt"
        output_path = target_dir / filename

        try:
            with output_path.open("w", encoding="utf-8") as f:
                for url in result.urls:
                    f.write(url + "\n")
            logger.info(f"âœ… ä¿å­˜å®Œäº†: {filename} ({len(result.urls)} ä»¶)")
            return True
        except IOError as e:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

class SubscriptionManager:
    def __init__(self, extractor: YouTubeExtractor, file_manager: FileManager):
        self.extractor = extractor
        self.file_manager = file_manager
        self.sub_file = CONFIG.OUTPUT_DIR / CONFIG.SUBSCRIPTION_FILE

    def process_subscriptions(self):
        if not self.sub_file.exists():
            logger.warning(f"âš ï¸ {CONFIG.SUBSCRIPTION_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            with self.sub_file.open("w", encoding="utf-8") as f:
                f.write("# ã“ã“ã«ãƒãƒ£ãƒ³ãƒãƒ«URLã‚’1è¡Œãšã¤è¨˜è¿°ã—ã¦ãã ã•ã„\n")
            logger.info(f"ğŸ†• ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {self.sub_file}")
            return

        with self.sub_file.open("r", encoding="utf-8") as f:
            urls = [line.strip() for line in f if line.strip() and not line.strip().startswith("#")]

        logger.info(f"ğŸ”„ ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³å·¡å›é–‹å§‹: {len(urls)} ä»¶")
        
        for i, url in enumerate(urls):
            logger.info(f"\n[{i+1}/{len(urls)}] å·¡å›ä¸­: {url}")
            for result in self.extractor.extract_iter(url):
                self.file_manager.save(result, CONFIG.OUTPUT_DIR)

# ==========================================
# 4. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“
# ==========================================
class UrlExtractorApp:
    def __init__(self):
        self.extractor = YouTubeExtractor()
        self.file_manager = FileManager()
        self.sub_manager = SubscriptionManager(self.extractor, self.file_manager)

    def run(self):
        print("=" * 50)
        print("   YouTube URL Extractor (v3.0.0)")
        print("=" * 50)

        parser = argparse.ArgumentParser()
        parser.add_argument("url", nargs="?", help="æŠ½å‡ºå¯¾è±¡ã®YouTube URL")
        parser.add_argument("--cron", action="store_true", help="ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³è‡ªå‹•å·¡å›ãƒ¢ãƒ¼ãƒ‰")
        args = parser.parse_args()

        if args.cron:
            self.sub_manager.process_subscriptions()
            logger.info("ğŸ‰ è‡ªå‹•å·¡å›å®Œäº†")
            return

        target_url = args.url
        if not target_url:
            try:
                target_url = input("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (Enterã§çµ‚äº†):\n> ").strip()
            except KeyboardInterrupt:
                sys.exit(0)

        if target_url:
            total_files = 0
            for result in self.extractor.extract_iter(target_url):
                if self.file_manager.save(result, CONFIG.OUTPUT_DIR):
                    total_files += 1
            logger.info(f"ğŸ‰ å‡¦ç†å®Œäº†: {total_files} ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")

if __name__ == "__main__":
    app = UrlExtractorApp()
    app.run()