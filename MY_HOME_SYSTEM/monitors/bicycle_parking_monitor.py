import requests
from bs4 import BeautifulSoup
import sys
import os
import argparse
import re
import traceback
from typing import List, TypedDict

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¸ã®ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import config
# ã€ä¿®æ­£ã€‘commonå»ƒæ­¢ -> coreãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸ç§»è¡Œ
from core.logger import setup_logging
from core.database import save_log_generic
from core.utils import get_now_iso

# ã€ä¿®æ­£ã€‘çµ±ä¸€ãƒ­ã‚¬ãƒ¼ã‚’ä½¿ç”¨
logger = setup_logging("bicycle_monitor")

# ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å®šç¾© (Type Hinting)
class ParkingRecord(TypedDict):
    area_name: str
    status_text: str
    waiting_count: int

class BicycleParkingMonitor:
    """
    é§è¼ªå ´ã®å®šæœŸåˆ©ç”¨å¾…æ©ŸçŠ¶æ³ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã€DBã«è¨˜éŒ²ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """
    
    def __init__(self) -> None:
        # Configã«å®šç¾©ãŒãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆURLã‚’ä½¿ç”¨
        self.url: str = getattr(config, "BICYCLE_PARKING_URL", "https://www.midi-kintetsu.com/mpns/pa/h-itami/teiki/index.php")
        self.table_name: str = getattr(config, "SQLITE_TABLE_BICYCLE", "bicycle_parking_logs")
        self.records: List[ParkingRecord] = []

    def fetch_and_parse(self) -> bool:
        """
        Webã‚µã‚¤ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€self.recordsã«æ ¼ç´ã™ã‚‹ã€‚
        """
        logger.info(f"Fetching data from: {self.url}")
        try:
            res = requests.get(self.url, timeout=15)
            res.encoding = res.apparent_encoding
            
            if res.status_code != 200:
                logger.error(f"HTTP Error: {res.status_code}")
                return False
                
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«ä¾å­˜ã—ãŸã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
            # (ä¼Šä¸¹ãƒ»éˆ´åŸã‚¨ãƒªã‚¢ã‚’å«ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã™ã‚‹)
            tables = soup.find_all('table')
            if not tables:
                logger.warning("No tables found on the page.")
                return False

            self.records = []
            
            # ç‰¹å®šã®ã‚¨ãƒªã‚¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            target_keywords = ["éˆ´åŸ", "ä¼Šä¸¹", "é˜ªæ€¥"]
            
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cols = row.find_all(['td', 'th'])
                    text_row = [c.get_text(strip=True) for c in cols]
                    
                    if len(text_row) >= 2:
                        area_name = text_row[0]
                        status_text = text_row[1] # "ç©ºãã‚ã‚Š", "å¾…ã¡äººæ•°ï¼š5äºº" etc.
                        
                        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒªã‚¢ã‹åˆ¤å®š
                        if any(k in area_name for k in target_keywords):
                            # å¾…ã¡äººæ•°ã‚’æŠ½å‡º (æ­£è¦è¡¨ç¾)
                            count = 0
                            match = re.search(r'(\d+)äºº', status_text)
                            if match:
                                count = int(match.group(1))
                            elif "ç©º" in status_text or "â—‹" in status_text:
                                count = 0
                            
                            self.records.append({
                                "area_name": area_name,
                                "status_text": status_text,
                                "waiting_count": count
                            })

            return True

        except Exception as e:
            logger.error(f"Scraping failed: {e}")
            logger.debug(traceback.format_exc())
            return False

    def save_to_db(self) -> None:
        """å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’DBã«ä¿å­˜ã™ã‚‹"""
        if not self.records:
            logger.info("No records to save.")
            return

        success_count = 0
        cols = ["timestamp", "area_name", "status_text", "waiting_count"]
        
        for r in self.records:
            try:
                vals = (
                    get_now_iso(),
                    r['area_name'],
                    r['status_text'],
                    r['waiting_count']
                )
                # ã€ä¿®æ­£ã€‘core.database.save_log_generic ã‚’ä½¿ç”¨
                if save_log_generic(self.table_name, cols, vals):
                    success_count += 1
            except Exception as e:
                logger.error(f"DBä¿å­˜ã‚¨ãƒ©ãƒ¼ ({r['area_name']}): {e}")

        logger.info(f"ğŸ’¾ {success_count}/{len(self.records)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é§è¼ªå ´å¾…æ©ŸçŠ¶æ³ãƒ¢ãƒ‹ã‚¿ãƒ¼")
    parser.add_argument("--save", action="store_true", help="DBã«ä¿å­˜ã™ã‚‹")
    args = parser.parse_args()

    # è‡ªå‹•å®Ÿè¡Œ(cron)ã‚’æƒ³å®šã—ã€printã§ã¯ãªãloggerã‚’ä½¿ç”¨
    logger.info("ğŸš² --- Bicycle Parking Monitor ---")
    monitor = BicycleParkingMonitor()
    
    is_success = monitor.fetch_and_parse()
    
    if is_success:
        logger.info(f"âœ… è§£æå®Œäº†: {len(monitor.records)} ä»¶ã®ã‚¨ãƒªã‚¢æƒ…å ±ã‚’å–å¾—")
        
        if monitor.records:
            for r in monitor.records:
                # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« INFO ã§çµæœã‚’å‡ºåŠ›
                logger.info(f"  - {r['area_name']}: {r['status_text']}")
            
            if args.save:
                monitor.save_to_db()
    else:
        sys.exit(1)