import os
import imaplib
import email
import pikepdf
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm  # ãƒ•ã‚©ãƒ³ãƒˆç®¡ç†ç”¨
import google.generativeai as genai
import json
import traceback
import time
from email.header import decode_header
from pdf2image import convert_from_path
from datetime import datetime
import config
import common

# === ãƒ­ã‚¬ãƒ¼è¨­å®š ===
logger = common.setup_logging("salary_analyzer")

# === Geminiè¨­å®š ===
if config.GEMINI_API_KEY:
    genai.configure(api_key=config.GEMINI_API_KEY)
else:
    logger.error("âŒ GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# === ã‚°ãƒ©ãƒ•ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š ===
def configure_fonts():
    """Matplotlibã§æ—¥æœ¬èªã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š"""
    try:
        # Raspberry Pi (Linux) ã§ä¸€èˆ¬çš„ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¢ã™
        font_candidates = ['Noto Sans CJK JP', 'IPAGothic', 'TakaoGothic', 'VL Gothic', 'WenQuanYi Micro Hei']
        found = False
        for f in font_candidates:
            try:
                # ãƒ•ã‚©ãƒ³ãƒˆãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚ã‚‹ã‹ç¢ºèª
                if fm.findfont(f):
                    plt.rcParams['font.family'] = f
                    logger.info(f"ğŸ¨ ã‚°ãƒ©ãƒ•ç”¨ãƒ•ã‚©ãƒ³ãƒˆã‚’ '{f}' ã«è¨­å®šã—ã¾ã—ãŸ")
                    found = True
                    break
            except:
                continue
        
        if not found:
            # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Japan1ï¼ˆæ±ç”¨ï¼‰ã‚’æŒ‡å®šã—ã¦ã¿ã‚‹
            plt.rcParams['font.family'] = 'sans-serif'
            plt.rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']
    except Exception as e:
        logger.warning(f"âš ï¸ ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

# åˆæœŸåŒ–æ™‚ã«ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å®Ÿè¡Œ
configure_fonts()

# === CSVã®ã‚«ãƒ©ãƒ å®šç¾© ===
CSV_COLUMN_ORDER = [
    "year", "month", "type", "employee_id", "name", "department",
    "net_payment", "total_payment", "total_deduction", "taxable_amount",
    "base_salary", "dependent_allowance", "adjustment_pay", "select_plan_subsidy",
    "commuting_allowance", "domestic_travel", "stock_incentive",
    "income_tax", "resident_tax", "health_insurance", "care_insurance",
    "welfare_pension", "pension_contribution", "employment_insurance",
    "ryoyu_fee", "mitsubishi_fee", "union_fee", "meal_cost", "dc_contribution",
    "life_insurance", "casualty_insurance", "stock_ownership", "melon_mutual_aid",
    "work_days", "work_hours", "overtime_ordinary", "overtime_midnight",
    "overtime_holiday", "paid_leave_remaining", "paid_leave_taken", "sick_leave"
]

class SalaryAnalyzer:
    def __init__(self):
        self.mail = None
        self.diagnose_environment()

    def diagnose_environment(self):
        logger.info("--- ğŸ¥ ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ ---")
        if not config.GEMINI_API_KEY: logger.error("âŒ APIã‚­ãƒ¼ãŒç©ºã§ã™ã€‚")
        else: logger.info("âœ… APIã‚­ãƒ¼è¨­å®šæ¸ˆã¿")

    def connect_gmail(self):
        try:
            self.mail = imaplib.IMAP4_SSL("imap.gmail.com")
            self.mail.login(config.GMAIL_USER, config.GMAIL_APP_PASSWORD)
            self.mail.select("inbox")
            logger.info("âœ… Gmailæ¥ç¶šæˆåŠŸ")
            return True
        except Exception as e:
            self._handle_error("Gmailæ¥ç¶šã‚¨ãƒ©ãƒ¼", e)
            return False

    def fetch_target_emails(self, limit=None):
        if not self.mail: return []
        sender = config.SALARY_MAIL_SENDER
        if not sender: return []
        try:
            status, messages = self.mail.search(None, 'X-GM-RAW', f'"from:{sender} has:attachment"')
            if status != "OK": return []
            email_ids = messages[0].split()
            if limit and len(email_ids) > limit: return email_ids[-limit:]
            return email_ids
        except Exception as e:
            self._handle_error("ãƒ¡ãƒ¼ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼", e)
            return []

    def unlock_pdf(self, input_path, output_path):
        for pwd in config.SALARY_PDF_PASSWORDS:
            try:
                with pikepdf.open(input_path, password=pwd) as pdf:
                    pdf.save(output_path)
                logger.info(f"ğŸ”“ PDFè§£é™¤æˆåŠŸ")
                return True
            except: continue
        logger.error("âŒ PDFãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è§£é™¤å¤±æ•—")
        return False

    def get_model_candidates(self):
        """
        åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
        â˜…å®Ÿé¨“çš„ãƒ¢ãƒ‡ãƒ«ã‚’é™¤å¤–ã—ã€å®‰å®šç‰ˆã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
        """
        return [
            # 1. æœ€æ–°ã®é«˜é€Ÿãƒ»è»½é‡ãƒ¢ãƒ‡ãƒ«ï¼ˆæ—§ 1.5-flash ã®å¾Œç¶™ï¼‰
            #    ç„¡æ–™æ ã§ã®åˆ¶é™ãŒæœ€ã‚‚ç·©ãã€çµ¦ä¸æ˜ç´°ã®èª­ã¿å–ã‚Šã«ã¯ååˆ†ãªæ€§èƒ½
            'models/gemini-2.5-flash',

            # 2. ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šãªã—ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆå¸¸ã«æœ€æ–°ã®Flashã‚’æŒ‡ã™ï¼‰
            'models/gemini-flash-latest',

            # 3. é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ï¼ˆFlashã§å¤±æ•—ã—ãŸæ™‚ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
            #    ç„¡æ–™æ ã§ã‚‚ä½¿ãˆã¾ã™ãŒã€Flashã‚ˆã‚Šå›æ•°åˆ¶é™ãŒå³ã—ã„ãŸã‚å¾Œã‚ã«é…ç½®
            'models/gemini-2.5-pro',
            
            # 4. é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
            'models/gemini-pro-latest'
        ]

    def analyze_with_gemini(self, image_path):
        uploaded_file = None
        try:
            model_list = self.get_model_candidates()
            logger.info("ğŸ“¤ ç”»åƒã‚’Geminiã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
            uploaded_file = genai.upload_file(path=image_path, display_name="Salary Slip")
            
            prompt = """
            ã“ã®çµ¦ä¸æ˜ç´°ç”»åƒã‚’åˆ†æã—ã€JSONãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            æ•°å€¤ã¯ã‚«ãƒ³ãƒãªã—ã®æ•´æ•°ã€‚ã€Œ0ã€ã‚„ã€Œç©ºæ¬„ã€ã¯ 0ã€‚å¹´æœˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰æ­£ç¢ºã«èª­ã¿å–ã‚‹ã“ã¨ã€‚

            {
                "year": 2025, "month": 11, "type": "çµ¦ä¸", 
                "employee_id": "ç¤¾å“¡ç•ªå·", "name": "æ°å", "department": "æ‰€å±ã‚³ãƒ¼ãƒ‰",

                // æ”¯çµ¦
                "base_salary": 0, "dependent_allowance": 0, "adjustment_pay": 0,
                "select_plan_subsidy": 0, "commuting_allowance": 0, "domestic_travel": 0,
                "stock_incentive": 0, "total_payment": 0,

                // æ§é™¤
                "income_tax": 0, "resident_tax": 0, "health_insurance": 0, "care_insurance": 0,
                "welfare_pension": 0, "pension_contribution": 0, "employment_insurance": 0,
                "ryoyu_fee": 0, "mitsubishi_fee": 0, "union_fee": 0, "meal_cost": 0,
                "dc_contribution": 0, "life_insurance": 0, "casualty_insurance": 0,
                "stock_ownership": 0, "melon_mutual_aid": 0, "total_deduction": 0,

                // åˆè¨ˆ
                "net_payment": 0, "taxable_amount": 0,

                // å‹¤æ€ 
                "work_days": 0, "work_hours": 0, "overtime_ordinary": 0, "overtime_midnight": 0,
                "overtime_holiday": 0, "paid_leave_remaining": 0, "paid_leave_taken": 0, "sick_leave": 0
            }
            """
            
            for model_name in model_list:
                try:
                    logger.info(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ« {model_name} ã§è§£æä¸­...")
                    model = genai.GenerativeModel(model_name)
                    res = model.generate_content([uploaded_file, prompt])
                    text = res.text.replace("```json", "").replace("```", "").strip()
                    data = json.loads(text)

                    if not data.get("year") or data.get("year") == 0:
                        logger.warning(f"âš ï¸ {model_name}: å¹´æœˆèª­ã¿å–ã‚Šå¤±æ•—ã€‚")
                        continue
                    
                    if data.get("net_payment", 0) == 0 and data.get("total_payment", 0) > 0:
                        data["net_payment"] = data["total_payment"] - data.get("total_deduction", 0)
                        
                    return data

                except Exception as e:
                    err_str = str(e)
                    if "429" in err_str or "Quota" in err_str:
                        logger.warning(f"âš ï¸ {model_name} åˆ©ç”¨æ ä¸Šé™(429)ã€‚10ç§’å¾…æ©Ÿã—ã¦æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ã¸...")
                        time.sleep(10)
                    else:
                        logger.warning(f"âš ï¸ {model_name} ã‚¨ãƒ©ãƒ¼: {e}")
            
            raise Exception("ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        except Exception as e:
            self._handle_error("Geminiåˆ†æã‚¨ãƒ©ãƒ¼", e)
            return None
        finally:
            if uploaded_file:
                try: uploaded_file.delete()
                except: pass

    def update_csv_database(self, data):
        if not data: return False
        try:
            csv_path = config.SALARY_CSV_PATH if data['type'] == "çµ¦ä¸" else config.BONUS_CSV_PATH
            if os.path.exists(csv_path): df = pd.read_csv(csv_path)
            else: df = pd.DataFrame(columns=CSV_COLUMN_ORDER)
            
            new_row = pd.DataFrame([data])
            for col in CSV_COLUMN_ORDER:
                if col not in new_row.columns: new_row[col] = 0
            for col in CSV_COLUMN_ORDER:
                if col not in df.columns: df[col] = 0
            
            new_row = new_row.reindex(columns=CSV_COLUMN_ORDER)
            df = df.reindex(columns=CSV_COLUMN_ORDER)

            df_combined = pd.concat([df, new_row])
            df_combined['year'] = pd.to_numeric(df_combined['year'], errors='coerce')
            df_combined['month'] = pd.to_numeric(df_combined['month'], errors='coerce')
            df_combined = df_combined.dropna(subset=['year', 'month'])
            
            df_combined = df_combined.drop_duplicates(subset=['year', 'month'], keep='last')
            df_combined = df_combined.sort_values(['year', 'month'])
            
            df_combined.to_csv(csv_path, index=False)
            logger.info(f"ğŸ’¾ CSVæ›´æ–°å®Œäº†: {csv_path}")
            return True
        except Exception as e:
            self._handle_error("CSVä¿å­˜ã‚¨ãƒ©ãƒ¼", e)
            return False

    def generate_graph(self, data_type="çµ¦ä¸"):
        csv_path = config.SALARY_CSV_PATH if data_type == "çµ¦ä¸" else config.BONUS_CSV_PATH
        if not os.path.exists(csv_path): return None
        try:
            df = pd.read_csv(csv_path)
            if df.empty: return None
            
            df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')
            df = df.dropna(subset=['date'])
            if df.empty: return None

            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šãŒåæ˜ ã•ã‚Œã‚‹ã‚ˆã†ã‚¿ã‚¤ãƒˆãƒ«ã«æ—¥æœ¬èªã‚’ä½¿ç”¨
            fig.suptitle(f"{data_type} ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", fontsize=20, fontweight='bold')
            plt.subplots_adjust(hspace=0.3, wspace=0.2)

            # 1. çµ¦ä¸æ¨ç§»
            ax1 = axes[0, 0]
            ax1.plot(df['date'], df['total_payment'], label='ç·æ”¯çµ¦', marker='o', linestyle='--', color='gray')
            ax1.plot(df['date'], df['net_payment'], label='æ‰‹å–ã‚Š', marker='o', linewidth=3, color='orange')
            ax1.plot(df['date'], df['total_deduction'], label='æ§é™¤', marker='x', linestyle=':', color='red')
            ax1.set_title("çµ¦ä¸æ¨ç§» (å††)")
            ax1.legend()
            ax1.grid(True, linestyle=':', alpha=0.6)
            ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))

            # 2. å‹¤æ€ 
            ax2 = axes[0, 1]
            ax2.bar(df['date'], df['work_hours'], label='åœ¨å ´æ™‚é–“', alpha=0.6, color='skyblue', width=20)
            ax2.set_title("å‹¤æ€ æ™‚é–“")
            ax2.legend()

            # 3. æ”¯çµ¦å†…è¨³
            ax3 = axes[1, 0]
            icols = ['base_salary', 'adjustment_pay', 'select_plan_subsidy', 'commuting_allowance']
            ilabs = ['åŸºæœ¬çµ¦', 'èª¿æ•´çµ¦', 'ã‚»ãƒ¬ã‚¯ãƒˆãƒ—ãƒ©ãƒ³', 'é€šå‹¤è²»']
            bottom = None
            for c, l in zip(icols, ilabs):
                if c in df.columns:
                    v = df[c].fillna(0)
                    ax3.bar(df['date'], v, label=l, bottom=bottom, width=20, alpha=0.8)
                    bottom = v if bottom is None else bottom + v
            ax3.set_title("æ”¯çµ¦å†…è¨³")
            ax3.legend()

            # 4. æ§é™¤å†…è¨³
            ax4 = axes[1, 1]
            dcols = ['income_tax', 'resident_tax', 'health_insurance', 'welfare_pension']
            dlabs = ['æ‰€å¾—ç¨', 'ä½æ°‘ç¨', 'å¥åº·ä¿é™º', 'åšç”Ÿå¹´é‡‘']
            bottom = None
            for c, l in zip(dcols, dlabs):
                if c in df.columns:
                    v = df[c].fillna(0)
                    ax4.bar(df['date'], v, label=l, bottom=bottom, width=20, alpha=0.8)
                    bottom = v if bottom is None else bottom + v
            ax4.set_title("æ§é™¤å†…è¨³")
            ax4.legend()

            graph_filename = f"dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            graph_path = os.path.join(config.SALARY_IMAGE_DIR, graph_filename)
            plt.savefig(graph_path, bbox_inches='tight')
            plt.close()
            return graph_path

        except Exception as e:
            self._handle_error("ã‚°ãƒ©ãƒ•ä½œæˆã‚¨ãƒ©ãƒ¼", e)
            return None

    def notify_user(self, result_data, graph_path):
        if not result_data: return
        
        msg_text = (
            f"ğŸ’° **çµ¦æ–™æ˜ç´°ãƒ¬ãƒãƒ¼ãƒˆ** ({result_data['year']}å¹´{result_data['month']}æœˆ)\n"
            f"ãŠä»•äº‹ãŠç–²ã‚Œæ§˜ã§ã—ãŸğŸµ ä»Šæœˆã‚‚ç„¡äº‹ã«ãƒ‡ãƒ¼ã‚¿ãŒå±Šãã¾ã—ãŸã‚ˆï¼\n\n"
            f"ğŸ’´ **æ‰‹å–ã‚Š: {result_data.get('net_payment',0):,} å††**\n"
            f"ğŸ¢ ç·æ”¯çµ¦: {result_data.get('total_payment',0):,} å††\n"
            f"ğŸ“‰ æ§é™¤è¨ˆ: {result_data.get('total_deduction',0):,} å††\n\n"
            f"å®¶è¨ˆã®ç®¡ç†ã«å½¹ç«‹ã¤ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸğŸ“Š"
        )
        
        if graph_path:
            with open(graph_path, 'rb') as f:
                image_data = f.read()
                common.send_push(config.LINE_USER_ID, [{"type": "text", "text": msg_text}], image_data=image_data, target="discord")
        else:
            common.send_push(config.LINE_USER_ID, [{"type": "text", "text": msg_text}], target="discord")
        logger.info("ğŸ“¨ Discordé€šçŸ¥é€ä¿¡å®Œäº†")

    def _handle_error(self, context, error):
        logger.error(f"{context}: {error}")
        err_msg = f"ğŸ˜° **System Error**\n{context}\n```{str(error)}```"
        common.send_push(config.LINE_USER_ID, [{"type": "text", "text": err_msg}], target="discord")

    def cleanup(self):
        if self.mail:
            try: self.mail.logout()
            except: pass

    def run(self, is_all_history=False, limit=None):
        logger.info("ğŸš€ çµ¦æ–™æ˜ç´°åˆ†æãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•")
        if not self.connect_gmail(): return
        
        limit_val = limit if limit is not None else (None if is_all_history else 3)
        email_ids = self.fetch_target_emails(limit_val)
        logger.info(f"ğŸ“© å¯¾è±¡ãƒ¡ãƒ¼ãƒ«: {len(email_ids)} ä»¶")
        
        processed = 0
        last_res, last_graph = None, None
        
        for i, e_id in enumerate(email_ids):
            try:
                # å‡¦ç†ã®åˆé–“ã«å¾…æ©Ÿ (APIåˆ¶é™å¯¾ç­–)
                if i > 0:
                    logger.info("â³ APIåˆ¶é™å›é¿ã®ãŸã‚5ç§’å¾…æ©Ÿä¸­...")
                    time.sleep(5)

                logger.info(f"ğŸ“¨ [{i+1}/{len(email_ids)}] ãƒ¡ãƒ¼ãƒ«å‡¦ç†é–‹å§‹...")
                _, msg_data = self.mail.fetch(e_id, "(RFC822)")
                msg = email.message_from_bytes(msg_data[0][1])
                
                subject, encoding = decode_header(msg["Subject"])[0]
                if isinstance(subject, bytes): subject = subject.decode(encoding if encoding else "utf-8")
                logger.info(f"   ä»¶å: {subject}")

                for part in msg.walk():
                    if part.get_filename() and part.get_filename().endswith(".pdf"):
                        tmp_pdf = os.path.join(config.SALARY_IMAGE_DIR, "temp.pdf")
                        unlocked = os.path.join(config.SALARY_IMAGE_DIR, "temp_ul.pdf")
                        with open(tmp_pdf, "wb") as f: f.write(part.get_payload(decode=True))
                        
                        if self.unlock_pdf(tmp_pdf, unlocked):
                            images = convert_from_path(unlocked, first_page=1, last_page=1)
                            if images:
                                img_path = os.path.join(config.SALARY_IMAGE_DIR, "target.jpg")
                                images[0].save(img_path, "JPEG")
                                res = self.analyze_with_gemini(img_path)
                                if res and self.update_csv_database(res):
                                    last_graph = self.generate_graph(res['type'])
                                    last_res = res
                                    processed += 1
                                    
                        if os.path.exists(tmp_pdf): os.remove(tmp_pdf)
                        if os.path.exists(unlocked): os.remove(unlocked)
            except Exception as e:
                self._handle_error(f"ãƒ¡ãƒ¼ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ (ID: {e_id})", e)
        
        if processed > 0:
            logger.info(f"ğŸ‰ åˆè¨ˆ {processed} ä»¶å‡¦ç†ã—ã¾ã—ãŸã€‚")
            self.notify_user(last_res, last_graph)
        else:
            logger.info("âœ¨ æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        self.cleanup()

if __name__ == "__main__":
    analyzer = SalaryAnalyzer()
    print("--- çµ¦æ–™æ˜ç´°åˆ†æãƒ„ãƒ¼ãƒ« (å®‰å®šç‰ˆ) ---")
    print("1: é€šå¸¸å®Ÿè¡Œ (æœ€æ–°ã®ãƒ¡ãƒ¼ãƒ«ã‚’ç¢ºèª)")
    print("2: å±¥æ­´å–è¾¼ (éå»ã®ãƒ¡ãƒ¼ãƒ«ã‚’å…¨ã¦ç¢ºèª)")
    print("3: ãŠè©¦ã—å®Ÿè¡Œ (æœ€æ–°5ä»¶ã®ã¿ç¢ºèª)")
    mode = input("ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ (1/2/3): ")
    if mode == "1": analyzer.run(False)
    elif mode == "2": analyzer.run(True)
    elif mode == "3": analyzer.run(True, limit=5)