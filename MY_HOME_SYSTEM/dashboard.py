# MY_HOME_SYSTEM/dashboard.py
import logging
import os
import shutil
import glob
import sqlite3
import subprocess
import traceback
from datetime import date, datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import pytz
import requests
import streamlit as st

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import common
import config
import tools.financial_service as financial_service
import train_service

# === ãƒ­ã‚¬ãƒ¼è¨­å®š ===
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# === å®šæ•°ãƒ»è¨­å®š ===
st.set_page_config(
    page_title="My Home Dashboard",
    page_icon="ğŸ ",
    layout="wide",
    initial_sidebar_state="collapsed",
)

FRIENDLY_NAME_FIXES: Dict[str, str] = {
    "ãƒªãƒ“ãƒ³ã‚°": "é«˜ç ‚ã®ãƒªãƒ“ãƒ³ã‚°",
    "ï¼‘Fã®æ´—é¢æ‰€": "é«˜ç ‚ã®æ´—é¢æ‰€",
    "å±…é–“": "ä¼Šä¸¹ã®ãƒªãƒ“ãƒ³ã‚°",
    "ä»•äº‹éƒ¨å±‹": "ä¼Šä¸¹ã®æ›¸æ–",
    "äººæ„Ÿã‚»ãƒ³ã‚µãƒ¼": "é«˜ç ‚ã®ãƒˆã‚¤ãƒ¬(äººæ„Ÿ)",
}

CUSTOM_CSS: str = """
<style>
    html, body, [class*="css"] { 
        font-family: "Helvetica Neue", Arial, "Hiragino Kaku Gothic ProN", "Hiragino Sans", Meiryo, sans-serif; 
    }
    .status-card {
        padding: 10px 5px;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        margin-bottom: 8px;
        height: 90px;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
    }
    .status-title {
        font-size: 0.8rem; color: #555; margin-bottom: 5px; font-weight: bold; opacity: 0.8;
    }
    .status-value {
        font-size: 1.1rem; font-weight: bold; line-height: 1.2; white-space: normal; 
    }
    .theme-green { background-color: #e8f5e9; color: #2e7d32; border: 1px solid #c8e6c9; }
    .theme-yellow { background-color: #fffde7; color: #f9a825; border: 1px solid #fff9c4; }
    .theme-red { background-color: #ffebee; color: #c62828; border: 1px solid #ffcdd2; }
    .theme-blue { background-color: #e3f2fd; color: #1565c0; border: 1px solid #bbdefb; }
    .theme-gray { background-color: #f5f5f5; color: #757575; border: 1px solid #e0e0e0; }
    
    .route-card {
        background-color: #fff; padding: 15px; border-radius: 10px; 
        border: 1px solid #ddd; margin-bottom: 10px; box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .route-path {
        margin-top: 15px; padding-top: 10px; border-top: 1px dashed #ccc; font-size: 0.95rem; color: #333;
    }
    .station-node { font-weight: bold; color: #000; }
    .line-node { color: #666; font-size: 0.85rem; margin: 0 5px; }
    .transfer-mark { color: #f57f17; font-weight:bold; margin: 0 5px; }
    
    .streamlit-expanderHeader {
        font-weight: bold; color: #0d47a1; background-color: #f0f8ff; border-radius: 5px;
    }
</style>
"""

# === ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: ãƒ‡ãƒ¼ã‚¿å‡¦ç† ===

def get_ro_db_connection() -> sqlite3.Connection:
    """
    èª­ã¿å–ã‚Šå°‚ç”¨ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ã—ã¾ã™ã€‚
    pandas.read_sql_queryç­‰ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã«Connectionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã—ã¾ã™ã€‚
    Note: å‘¼ã³å‡ºã—å…ƒã§å¿…ãš close() ã™ã‚‹ã‹ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    """
    # æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¸è¥²ã—ã€READ ONLYãƒ¢ãƒ¼ãƒ‰ã‚’æŒ‡å®š
    return sqlite3.connect(
        f"file:{config.SQLITE_DB_PATH}?mode=ro", uri=True, timeout=10.0
    )


def process_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """DataFrameã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ—¥æœ¬æ™‚é–“ã«å¤‰æ›ã—ã€è¡¨ç¤ºåã‚’é©ç”¨ã™ã‚‹å…±é€šå‡¦ç†"""
    if df.empty or "timestamp" not in df.columns:
        return df

    # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å¤‰æ›
    # ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦è­¦å‘Šã‚’æŠ‘åˆ¶
    df = df.copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    
    if df["timestamp"].dt.tz is None:
        df["timestamp"] = df["timestamp"].dt.tz_localize("UTC").dt.tz_convert("Asia/Tokyo")
    else:
        df["timestamp"] = df["timestamp"].dt.tz_convert("Asia/Tokyo")

    return df


def apply_friendly_names(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ‡ãƒã‚¤ã‚¹IDã‹ã‚‰è¡¨ç¤ºåã¸ã®å¤‰æ›ã¨ã€ç‰¹å®šã®åç§°ç½®æ›ã‚’è¡Œã†"""
    if df.empty:
        return df

    df = df.copy()

    # 0. ã‚«ãƒ©ãƒ åã®æºã‚‰ãå¸å
    if "device_id" not in df.columns and "camera_id" in df.columns:
        df["device_id"] = df["camera_id"]

    # 1. å¿…é ˆã‚«ãƒ©ãƒ  'device_id' ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if "device_id" not in df.columns:
        # UIãŒè½ã¡ãªã„ã‚ˆã†ã«æœ€ä½é™ã®åˆ—ã‚’åŸ‹ã‚ã‚‹
        df["friendly_name"] = "Unknown"
        df["location"] = "ãã®ä»–"
        return df

    # 2. Configã‹ã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    id_map = {d["id"]: d.get("name", d["id"]) for d in config.MONITOR_DEVICES}
    
    # 3. ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ—ã®ä½œæˆ
    loc_map = {d["id"]: d.get("location", "ãã®ä»–") for d in config.MONITOR_DEVICES}

    # 4. DBå†…ã®ã€Œæœ€æ–°ã®ãƒ‡ãƒã‚¤ã‚¹åã€ã‚’å–å¾—ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¸Šæ›¸ã
    #    (æ³¨: è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã®çµ±åˆãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€device_nameãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã‚‚ã‚ã‚‹ãŸã‚ãƒã‚§ãƒƒã‚¯)
    if "device_name" in df.columns and "timestamp" in df.columns:
        try:
            latest_df = df.sort_values("timestamp", ascending=False)
            latest_df = latest_df.drop_duplicates(subset="device_id", keep="first")
            valid_latest = latest_df[latest_df["device_name"].notna() & (latest_df["device_name"] != "")]
            db_latest_map = valid_latest.set_index("device_id")["device_name"].to_dict()
            id_map.update(db_latest_map)
        except Exception as e:
            logger.warning(f"Friendly name mapping update failed: {e}")

    # 5. ãƒãƒƒãƒ”ãƒ³ã‚°ã®é©ç”¨
    df["friendly_name"] = df["device_id"].map(id_map)
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°ã§è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã¯ device_name -> device_id ã®é †ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if "device_name" in df.columns:
        df["friendly_name"] = df["friendly_name"].fillna(df["device_name"])
    df["friendly_name"] = df["friendly_name"].fillna(df["device_id"])

    # 6. ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é©ç”¨
    df["location"] = df["device_id"].map(loc_map).fillna("ãã®ä»–")

    # 7. åç§°ã®å¾®èª¿æ•´
    df["friendly_name"] = df["friendly_name"].replace(FRIENDLY_NAME_FIXES)

    return df


@st.cache_data(ttl=60)
def load_data_from_db(query: str, date_column: str = "timestamp") -> pd.DataFrame:
    """æ±ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–¢æ•°"""
    conn = None
    try:
        conn = get_ro_db_connection()
        df = pd.read_sql_query(query, conn)
        
        if date_column in df.columns:
            if date_column != "timestamp":
                df.rename(columns={date_column: "timestamp"}, inplace=True)
            
            df = process_dataframe(df)
            
            if date_column != "timestamp":
                df.rename(columns={"timestamp": date_column}, inplace=True)

        return df
    except Exception as e:
        logger.error(f"Data Load Error (Query: {query[:30]}...): {e}")
        return pd.DataFrame()
    finally:
        if conn:
            conn.close()


def load_nas_status() -> Optional[pd.Series]:
    """NASã®æœ€æ–°çŠ¶æ…‹ã‚’å–å¾—"""
    table_name = getattr(config, "SQLITE_TABLE_NAS", "nas_records")
    conn = None
    try:
        conn = get_ro_db_connection()
        cur = conn.cursor()
        cur.execute(
            f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'"
        )
        if not cur.fetchone():
            return None
        cur.close()
        conn.close()
        conn = None

        query = f"SELECT * FROM {table_name} ORDER BY timestamp DESC LIMIT 1"
        df = load_data_from_db(query)
        return df.iloc[0] if not df.empty else None
    except Exception as e:
        logger.error(f"NAS Data Load Error: {e}")
        if conn:
            conn.close()
        return None


# å€‹åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–¢æ•°ç¾¤
def load_generic_data(table_name: str, limit: int = 500) -> pd.DataFrame:
    query = f"SELECT * FROM {table_name} ORDER BY timestamp DESC LIMIT {limit}"
    return load_data_from_db(query)


def load_sensor_data(limit: int = 5000) -> pd.DataFrame:
    """
    ã€v1.0.0å¯¾å¿œã€‘æ–°æ—§ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦å–å¾—ã™ã‚‹
    Target Tables:
      1. device_records (Legacy / Other sensors)
      2. switchbot_meter_logs (Temperature / Humidity)
      3. power_usage (Electricity)
    """
    # 1. Legacy / Others (é–‹é–‰ã‚»ãƒ³ã‚µãƒ¼ç­‰)
    query_legacy = f"""
        SELECT timestamp, device_id, device_name, device_type, 
               temperature_celsius, humidity_percent, power_watts, 
               contact_state, movement_state, brightness_state
        FROM device_records 
        ORDER BY timestamp DESC LIMIT {limit}
    """
    df_legacy = load_data_from_db(query_legacy)

    # 2. SwitchBot Meter Logs (New: æ¸©æ¹¿åº¦)
    # ã‚«ãƒ©ãƒ åã‚’æ—§ä»•æ§˜ (temperature_celsius, humidity_percent) ã«ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã—ã¦å–å¾—
    query_meter = f"""
        SELECT timestamp, device_id, device_name, 
               temperature as temperature_celsius, 
               humidity as humidity_percent
        FROM {config.SQLITE_TABLE_SWITCHBOT_LOGS}
        ORDER BY timestamp DESC LIMIT {limit}
    """
    df_meter = load_data_from_db(query_meter)
    if not df_meter.empty:
        df_meter["device_type"] = "Meter"

    # 3. Power Usage (New: é›»åŠ›)
    # ã‚«ãƒ©ãƒ åã‚’æ—§ä»•æ§˜ (power_watts) ã«ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã—ã¦å–å¾—
    query_power = f"""
        SELECT timestamp, device_id, device_name, 
               wattage as power_watts
        FROM {config.SQLITE_TABLE_POWER_USAGE}
        ORDER BY timestamp DESC LIMIT {limit}
    """
    df_power = load_data_from_db(query_power)
    if not df_power.empty:
        # Nature Remo E Lite ã‹ Plug ã‹ã¯ device_name ç­‰ã§åŒºåˆ¥ãŒå¿…è¦ã ãŒã€
        # ã„ã£ãŸã‚“ 'Nature Remo E Lite' ã¨ä»®å®šã™ã‚‹ã‹ã€æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã«ä»»ã›ã‚‹
        # ã“ã“ã§ã¯å¾Œæ®µã®ãƒ­ã‚¸ãƒƒã‚¯ãŒ device_type='Nature Remo E Lite' ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ç®‡æ‰€ãŒã‚ã‚‹ãŸã‚è£œå®Œ
        df_power["device_type"] = df_power["device_name"].apply(
            lambda x: "Nature Remo E Lite" if x and "Remo" in str(x) else "Plug"
        )
        # device_nameãŒãªã„å ´åˆ
        df_power["device_type"] = df_power["device_type"].replace("Plug", "Nature Remo E Lite") 

    # --- çµ±åˆ ---
    df_list = []
    if not df_legacy.empty: df_list.append(df_legacy)
    if not df_meter.empty: df_list.append(df_meter)
    if not df_power.empty: df_list.append(df_power)

    if not df_list:
        return pd.DataFrame()

    df_merged = pd.concat(df_list, ignore_index=True)
    
    # çµ±åˆå¾Œã®å†ã‚½ãƒ¼ãƒˆ
    if "timestamp" in df_merged.columns:
        # load_data_from_db ã§æ—¢ã«å‹å¤‰æ›ã•ã‚Œã¦ã„ã‚‹ã¯ãšã ãŒå¿µã®ãŸã‚
        df_merged["timestamp"] = pd.to_datetime(df_merged["timestamp"])
        df_merged = df_merged.sort_values("timestamp", ascending=False).reset_index(drop=True)

    # è¡¨ç¤ºåé©ç”¨
    return apply_friendly_names(df_merged).head(limit)


def get_ngrok_url() -> Dict[str, str]:
    """ngrokã®ç¾åœ¨ã®å…¬é–‹URLã‚’å–å¾—ã™ã‚‹"""
    try:
        res = requests.get("http://127.0.0.1:4040/api/tunnels", timeout=2)
        if res.status_code == 200:
            data = res.json()
            urls = {}
            for t in data.get("tunnels", []):
                addr = t.get("config", {}).get("addr", "")
                if "8000" in addr:
                    urls["server"] = t.get("public_url")
                elif "8501" in addr:
                    urls["dashboard"] = t.get("public_url")
            return urls
    except Exception:
        pass
    return {}


def get_disk_usage() -> Optional[Dict[str, float]]:
    """ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã‚’å–å¾—"""
    try:
        total, used, free = shutil.disk_usage("/")
        return {
            "total_gb": total // (2**30),
            "used_gb": used // (2**30),
            "free_gb": free // (2**30),
            "percent": (used / total) * 100,
        }
    except Exception as e:
        logger.error(f"Disk usage check failed: {e}")
        return None


def get_memory_usage() -> Optional[Dict[str, float]]:
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚’å–å¾—"""
    try:
        res = subprocess.run(["free", "-m"], capture_output=True, text=True, check=False)
        lines = res.stdout.strip().split("\n")

        if len(lines) >= 2:
            parts = lines[1].split()
            total = int(parts[1])
            used = int(parts[2])
            available = int(parts[6])

            percent = (used / total) * 100 if total > 0 else 0

            return {
                "total_mb": total,
                "used_mb": used,
                "available_mb": available,
                "percent": percent,
            }
    except Exception as e:
        logger.error(f"Memory check failed: {e}")
        pass
    return None


def get_system_logs(lines: int = 50, priority: Optional[str] = None, target_date: Optional[date] = None) -> str:
    """Systemdã®ãƒ­ã‚°ã‚’å–å¾—"""
    try:
        cmd = ["journalctl", "-u", "home_system.service", "--no-pager"]
        if target_date:
            since_str = f"{target_date} 00:00:00"
            until_str = f"{target_date} 23:59:59"
            cmd.extend(["--since", since_str, "--until", until_str, "-n", "5000"])
        else:
            cmd.extend(["-n", str(lines)])

        if priority:
            cmd.extend(["-p", priority])

        res = subprocess.run(cmd, capture_output=True, text=True, check=False)
        return res.stdout
    except Exception as e:
        return f"ãƒ­ã‚°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"


@st.cache_data(ttl=300)
def load_weather_history(days: int = 40, location: str = "ä¼Šä¸¹") -> pd.DataFrame:
    start_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
    query = f"""
        SELECT date, min_temp, max_temp, weather_desc, umbrella_level 
        FROM weather_history 
        WHERE location = '{location}' AND date >= '{start_date}'
    """
    try:
        conn = get_ro_db_connection()
        df = pd.read_sql_query(query, conn)
        return df
    except Exception as e:
        logger.error(f"Weather Load Error: {e}")
        return pd.DataFrame()
    finally:
        if 'conn' in locals() and conn:
            conn.close()


@st.cache_data(ttl=3600)
def load_yearly_temperature_stats(year: int, location: str = "ä¼Šä¸¹") -> pd.DataFrame:
    """æŒ‡å®šå¹´ã®å¤–æ°—æ¸©ã¨å®¤æ¸©(ä¼Šä¸¹)ã®æ—¥æ¬¡çµ±è¨ˆã‚’å–å¾—"""
    conn = get_ro_db_connection()
    try:
        start_date = f"{year}-01-01"
        end_date = f"{year}-12-31"

        q_weather = f"""
            SELECT date, max_temp as out_max, min_temp as out_min
            FROM weather_history
            WHERE location = '{location}' AND date >= '{start_date}' AND date <= '{end_date}'
        """
        df_weather = pd.read_sql_query(q_weather, conn)

        # æ¸©å®¤åº¦ã®å–å¾—ï¼šload_sensor_data ã¯é‡ã„ã®ã§ç›´æ¥SQLã§é›†è¨ˆã™ã‚‹
        # ã“ã“ã‚‚æ–°æ—§ãƒ†ãƒ¼ãƒ–ãƒ«ä¸¡æ–¹ã‚’è¦‹ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€ç°¡ç•¥åŒ–ã®ãŸã‚æ–°ãƒ†ãƒ¼ãƒ–ãƒ«å„ªå…ˆã§çµåˆ
        
        # ä¼Šä¸¹ã®ãƒ‡ãƒã‚¤ã‚¹IDã‚’å–å¾—
        itami_ids = [
            d["id"] for d in config.MONITOR_DEVICES if d.get("location") == location
        ]
        if not itami_ids:
            return df_weather
            
        ids_str = "'" + "','".join(itami_ids) + "'"

        # æ–°ãƒ†ãƒ¼ãƒ–ãƒ« (switchbot_meter_logs) ã‹ã‚‰é›†è¨ˆ
        q_new = f"""
            SELECT 
                substr(timestamp, 1, 10) as date,
                MAX(temperature) as in_max,
                MIN(temperature) as in_min
            FROM {config.SQLITE_TABLE_SWITCHBOT_LOGS}
            WHERE 
                timestamp >= '{start_date}' AND timestamp <= '{end_date}T23:59:59'
                AND device_id IN ({ids_str})
                AND temperature IS NOT NULL
            GROUP BY date
        """
        
        # æ—§ãƒ†ãƒ¼ãƒ–ãƒ« (device_records) ã‹ã‚‰é›†è¨ˆ
        q_old = f"""
            SELECT 
                substr(timestamp, 1, 10) as date,
                MAX(temperature_celsius) as in_max,
                MIN(temperature_celsius) as in_min
            FROM device_records
            WHERE 
                timestamp >= '{start_date}' AND timestamp <= '{end_date}T23:59:59'
                AND device_id IN ({ids_str})
                AND temperature_celsius IS NOT NULL
            GROUP BY date
        """
        
        # å®Ÿè¡Œã¨çµåˆ
        df_new = pd.DataFrame()
        df_old = pd.DataFrame()
        
        try:
            df_new = pd.read_sql_query(q_new, conn)
        except Exception:
            pass # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒãªã„å ´åˆãªã©
            
        try:
            df_old = pd.read_sql_query(q_old, conn)
        except Exception:
            pass

        # çµåˆå‡¦ç†
        if not df_new.empty and not df_old.empty:
            df_sensor = pd.concat([df_new, df_old]).groupby("date").agg({
                "in_max": "max",
                "in_min": "min"
            }).reset_index()
        elif not df_new.empty:
            df_sensor = df_new
        else:
            df_sensor = df_old

        if df_weather.empty and df_sensor.empty:
            return pd.DataFrame()

        if df_weather.empty:
            df_merged = df_sensor
        elif df_sensor.empty:
            df_merged = df_weather
        else:
            df_merged = pd.merge(df_weather, df_sensor, on="date", how="outer")

        return df_merged.sort_values("date")

    except Exception as e:
        logger.error(f"Yearly Temp Load Error: {e}")
        return pd.DataFrame()
    finally:
        conn.close()


@st.cache_data(ttl=3600)
def load_ranking_dates(limit: int = 3) -> List[str]:
    conn = get_ro_db_connection()
    try:
        cur = conn.cursor()
        cur.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name='app_rankings'"
        )
        if not cur.fetchone():
            return []

        query = f"SELECT DISTINCT date FROM app_rankings ORDER BY date DESC LIMIT {limit}"
        df = pd.read_sql_query(query, conn)
        return df["date"].tolist()
    except Exception as e:
        logger.error(f"Ranking Dates Load Error: {e}")
        return []
    finally:
        conn.close()


@st.cache_data(ttl=3600)
def load_ranking_data(date_str: str, ranking_type: str) -> pd.DataFrame:
    conn = get_ro_db_connection()
    try:
        query = f"""
            SELECT rank, title, app_id 
            FROM app_rankings 
            WHERE date = '{date_str}' AND ranking_type = '{ranking_type}'
            ORDER BY rank ASC
        """
        return pd.read_sql_query(query, conn)
    except Exception as e:
        logger.error(f"Ranking Data Load Error: {e}")
        return pd.DataFrame()
    finally:
        conn.close()


@st.cache_data(ttl=3600)
def load_bicycle_data(limit: int = 2000) -> pd.DataFrame:
    table_name = getattr(config, "SQLITE_TABLE_BICYCLE", "bicycle_parking_records")
    conn = None
    try:
        conn = get_ro_db_connection()
        cur = conn.cursor()
        cur.execute(
            f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'"
        )
        if not cur.fetchone():
            return pd.DataFrame()
        conn.close()
        conn = None

        query = f"SELECT * FROM {table_name} ORDER BY timestamp DESC LIMIT {limit}"
        return load_data_from_db(query)
    except Exception as e:
        logger.error(f"Bicycle Data Load Error: {e}")
        if conn:
            conn.close()
        return pd.DataFrame()


def load_ai_report() -> Optional[pd.Series]:
    query = f"SELECT * FROM {config.SQLITE_TABLE_AI_REPORT} ORDER BY id DESC LIMIT 1"
    df = load_data_from_db(query)
    return df.iloc[0] if not df.empty else None


def calculate_monthly_cost_cumulative() -> int:
    """ä»Šæœˆã®é›»æ°—ä»£æ¦‚ç®— (v1.0.0å¯¾å¿œ: power_usageå„ªå…ˆ)"""
    try:
        now = datetime.now(pytz.timezone("Asia/Tokyo"))
        start_of_month = now.replace(day=1, hour=0, minute=0, second=0).isoformat()

        # 1. æ–°ãƒ†ãƒ¼ãƒ–ãƒ« (power_usage) ã‹ã‚‰å–å¾—
        query = f"""
            SELECT timestamp, wattage as power_watts 
            FROM {config.SQLITE_TABLE_POWER_USAGE} 
            WHERE timestamp >= '{start_of_month}'
            ORDER BY timestamp ASC
        """
        df = load_data_from_db(query)

        # 2. æ–°ãƒ†ãƒ¼ãƒ–ãƒ«ãŒç©ºãªã‚‰æ—§ãƒ†ãƒ¼ãƒ–ãƒ« (device_records) ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if df.empty:
            query_old = f"""
                SELECT timestamp, power_watts FROM device_records
                WHERE device_type = 'Nature Remo E Lite' AND timestamp >= '{start_of_month}'
                ORDER BY timestamp ASC
            """
            df = load_data_from_db(query_old)

        if df.empty:
            return 0

        df["time_diff"] = df["timestamp"].diff().dt.total_seconds() / 3600
        df = df.dropna(subset=["time_diff"])
        df = df[df["time_diff"] <= 1.0] # ç•°å¸¸ãªé–“éš”ã‚’é™¤å¤–

        df["kwh"] = (df["power_watts"] / 1000) * df["time_diff"]
        # æ¦‚ç®—å˜ä¾¡ 31å††/kWh
        return int(df["kwh"].sum() * 31)
    except Exception as e:
        logger.error(f"Cost Calc Error: {e}")
        return 0


# === ãƒ­ã‚¸ãƒƒã‚¯å±¤: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š ===


def get_takasago_status(df_sensor: pd.DataFrame, now: datetime) -> Tuple[str, str]:
    """é«˜ç ‚ã®å®Ÿå®¶ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š"""
    val = "âšª ãƒ‡ãƒ¼ã‚¿ãªã—"
    theme = "theme-gray"

    if df_sensor.empty:
        return val, theme

    df_taka = df_sensor[
        (df_sensor["location"] == "é«˜ç ‚")
        & (df_sensor["contact_state"].isin(["open", "detected"]))
    ]

    if not df_taka.empty:
        last_active = df_taka.iloc[0]["timestamp"]
        diff_min = (now - last_active).total_seconds() / 60

        if diff_min < 60:
            val = "ğŸŸ¢ å…ƒæ°— (1hä»¥å†…)"
            theme = "theme-green"
        elif diff_min < 180:
            val = "ğŸŸ¡ é™ã‹ (3hä»¥å†…)"
            theme = "theme-yellow"
        else:
            val = f"ğŸ”´ {int(diff_min/60)}æ™‚é–“ å‹•ããªã—"
            theme = "theme-red"

    return val, theme


def get_itami_status(df_sensor: pd.DataFrame, now: datetime) -> Tuple[str, str]:
    """ä¼Šä¸¹ï¼ˆè‡ªå®…ï¼‰ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š"""
    val = "âšª ãƒ‡ãƒ¼ã‚¿ãªã—"
    theme = "theme-gray"

    if df_sensor.empty:
        return val, theme

    # äººæ„Ÿã‚»ãƒ³ã‚µãƒ¼å„ªå…ˆ
    df_motion = df_sensor[
        (df_sensor["location"] == "ä¼Šä¸¹")
        & (df_sensor["device_type"].str.contains("Motion", na=False))
        & (df_sensor["movement_state"] == "detected")
    ].sort_values("timestamp", ascending=False)

    if not df_motion.empty:
        last_mov = df_motion.iloc[0]["timestamp"]
        diff_m = (now - last_mov).total_seconds() / 60

        if diff_m < 10:
            val = "ğŸŸ¢ æ´»å‹•ä¸­ (ä»Š)"
            theme = "theme-green"
        elif diff_m < 60:
            val = f"ğŸŸ¢ æ´»å‹•ä¸­ ({int(diff_m)}åˆ†å‰)"
            theme = "theme-green"
        else:
            val = f"ğŸŸ¡ é™ã‹ ({int(diff_m/60)}hå‰)"
            theme = "theme-yellow"
    else:
        # é–‹é–‰ã‚»ãƒ³ã‚µãƒ¼
        df_contact = df_sensor[
            (df_sensor["location"] == "ä¼Šä¸¹") & (df_sensor["contact_state"] == "open")
        ].sort_values("timestamp", ascending=False)

        if not df_contact.empty:
            last_c = df_contact.iloc[0]["timestamp"]
            diff_c = (now - last_c).total_seconds() / 60
            if diff_c < 60:
                val = f"ğŸŸ¢ æ´»å‹•ä¸­ ({int(diff_c)}åˆ†å‰)"
                theme = "theme-green"

    return val, theme


def get_rice_status(df_sensor: pd.DataFrame, now: datetime) -> Tuple[str, str]:
    """ç‚Šé£¯å™¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š: ãã®æ—¥ã®æœ€å¤§é›»åŠ›ãŒ500Wè¶…ã‹ã§åˆ¤å®š"""
    val = "ğŸš ç‚Šã„ã¦ãªã„"
    theme = "theme-red"

    # device_nameã‚«ãƒ©ãƒ ãŒãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ãƒã‚§ãƒƒã‚¯
    if "device_name" not in df_sensor.columns or "power_watts" not in df_sensor.columns:
        return val, theme

    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    
    # ãƒ¡ãƒ¢ãƒªä¸Šã®DataFrameã‹ã‚‰åˆ¤å®šï¼ˆé‡ã„ã‚¯ã‚¨ãƒªã‚’é¿ã‘ã‚‹ï¼‰
    df_rice = df_sensor[
        (df_sensor["device_name"].astype(str).str.contains("ç‚Šé£¯å™¨")) &
        (df_sensor["timestamp"] >= today_start)
    ]

    if not df_rice.empty:
        max_watts = df_rice["power_watts"].max()
        if max_watts is not None and max_watts >= 500:
            val = "ğŸš ã”é£¯ã‚ã‚Š"
            theme = "theme-green"

    return val, theme


def get_traffic_status() -> Tuple[str, str, Dict, Dict]:
    """äº¤é€šæƒ…å ±ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    jr_status = train_service.get_jr_traffic_status()
    line_g = jr_status["å®å¡šç·š"]
    line_a = jr_status["ç¥æˆ¸ç·š"]

    if line_g.get("is_suspended") or line_a.get("is_suspended"):
        return "â›” é‹ä¼‘ç™ºç”Ÿ", "theme-red", line_g, line_a
    elif line_g["is_delay"] or line_a["is_delay"]:
        return "âš ï¸ é…å»¶ã‚ã‚Š", "theme-yellow", line_g, line_a
    else:
        return "ğŸŸ¢ å¹³å¸¸é‹è»¢", "theme-green", line_g, line_a


def get_car_status(df_car: pd.DataFrame) -> Tuple[str, str]:
    """è»Šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    val = "ğŸ  åœ¨å®…"
    theme = "theme-green"
    if not df_car.empty and df_car.iloc[0]["action"] == "LEAVE":
        val = "ğŸš— å¤–å‡ºä¸­"
        theme = "theme-yellow"
    return val, theme


def get_bicycle_status(df_bicycle: pd.DataFrame) -> Tuple[str, str]:
    """é§è¼ªå ´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ (ä¸»è¦3ã‚¨ãƒªã‚¢ã®å€‹åˆ¥è¡¨ç¤º + å‰æ—¥æ¯”)"""
    if df_bicycle.empty:
        return "âšª ãƒ‡ãƒ¼ã‚¿ãªã—", "theme-gray"

    targets = {
        "JRä¼Šä¸¹é§…å‰(ç¬¬1)è‡ªè»¢è»Šé§è»Šå ´ (A)": "ç¬¬1A",
        "JRä¼Šä¸¹é§…å‰(ç¬¬3)è‡ªè»¢è»Šé§è»Šå ´ (A)": "ç¬¬3A",
        "JRä¼Šä¸¹é§…å‰(ç¬¬3)è‡ªè»¢è»Šé§è»Šå ´ (E)": "ç¬¬3E",
    }

    if not pd.api.types.is_datetime64_any_dtype(df_bicycle["timestamp"]):
        df_bicycle = df_bicycle.copy()
        df_bicycle["timestamp"] = pd.to_datetime(df_bicycle["timestamp"]).dt.tz_convert(
            "Asia/Tokyo"
        )

    latest_df = df_bicycle.sort_values(
        "timestamp", ascending=False
    ).drop_duplicates("area_name")

    details = []
    total_wait = 0
    has_data = False

    for full_name, short_name in targets.items():
        row = latest_df[latest_df["area_name"] == full_name]

        if not row.empty:
            current_val = int(row.iloc[0]["waiting_count"])
            current_time = row.iloc[0]["timestamp"]

            df_area = df_bicycle[df_bicycle["area_name"] == full_name]
            target_time = current_time - timedelta(days=1)
            
            df_near = df_area[
                (df_area["timestamp"] >= target_time - timedelta(hours=2))
                & (df_area["timestamp"] <= target_time + timedelta(hours=2))
            ]

            diff_str = ""
            if not df_near.empty:
                nearest_idx = (df_near["timestamp"] - target_time).abs().idxmin()
                past_val = int(df_near.loc[nearest_idx]["waiting_count"])

                diff = current_val - past_val
                if diff > 0:
                    diff_str = f" <span style='color:#d32f2f;'>(ğŸ”º{diff})</span>"
                elif diff < 0:
                    diff_str = f" <span style='color:#388e3c;'>(ğŸ”»{abs(diff)})</span>"
                else:
                    diff_str = f" <span style='color:#757575;'>(â¡ï¸0)</span>"
            else:
                diff_str = " <span style='color:#999;'>(--)</span>"

            details.append(f"{short_name}: <b>{current_val}</b>å°{diff_str}")
            total_wait += current_val
            has_data = True
        else:
            details.append(f"{short_name}: -")

    if not has_data:
        return "âšª ãƒ‡ãƒ¼ã‚¿ãªã—", "theme-gray"

    val = f"<div style='font-size:0.85rem; line-height:1.4; text-align:left; display:inline-block;'>{'<br>'.join(details)}</div>"

    if total_wait == 0:
        theme = "theme-green"
    elif total_wait < 10:
        theme = "theme-yellow"
    else:
        theme = "theme-red"

    return val, theme


def get_server_status() -> Tuple[str, str]:
    """ã‚µãƒ¼ãƒãƒ¼ç¨¼åƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    mem = get_memory_usage()
    if mem:
        val = f"ğŸ’» RAM: {int(mem['percent'])}%"
        theme = "theme-green" if mem["percent"] < 80 else "theme-red"
    else:
        val = "âšª å–å¾—å¤±æ•—"
        theme = "theme-gray"
    return val, theme


def get_nas_status_simple(nas_data: Optional[pd.Series]) -> Tuple[str, str]:
    """NASç°¡æ˜“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    if nas_data is None:
        return "âšª ãƒ‡ãƒ¼ã‚¿ãªã—", "theme-gray"

    try:
        if nas_data["status_ping"] == "OK":
            val = "ğŸ—„ï¸ NAS: ç¨¼åƒä¸­"
            theme = "theme-green"
        else:
            val = "âš ï¸ NAS: å¿œç­”ãªã—"
            theme = "theme-red"
    except KeyError:
        val = "âš ï¸ NAS: ãƒ‡ãƒ¼ã‚¿ç•°å¸¸"
        theme = "theme-yellow"

    return val, theme


# === UIå±¤: æç”»ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ ===


def render_status_card_html(title: str, value: str, theme: str) -> str:
    return f"""
    <div class="status-card {theme}">
        <div class="status-title">{title}</div>
        <div class="status-value">{value}</div>
    </div>
    """


def render_dashboard_summary(
    now: datetime,
    df_sensor: pd.DataFrame,
    df_car: pd.DataFrame,
    df_bicycle: pd.DataFrame,
    nas_data: Optional[pd.Series],
):
    """ãƒˆãƒƒãƒ—ç”»é¢ã®ã‚µãƒãƒªãƒ¼ï¼ˆ3x3 ã‚°ãƒªãƒƒãƒ‰ï¼‰ã‚’æç”»"""

    # --- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾— ---
    taka_val, taka_theme = get_takasago_status(df_sensor, now)
    itami_val, itami_theme = get_itami_status(df_sensor, now)
    car_val, car_theme = get_car_status(df_car)

    rice_val, rice_theme = get_rice_status(df_sensor, now)
    cost = calculate_monthly_cost_cumulative()
    elec_val = f"âš¡ {cost:,} å††"
    bicycle_val, bicycle_theme = get_bicycle_status(df_bicycle)

    traffic_val, traffic_theme, _, _ = get_traffic_status()
    server_val, server_theme = get_server_status()
    nas_val, nas_theme = get_nas_status_simple(nas_data)

    # --- æç”» (3åˆ—x3è¡Œ) ---
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown(
            render_status_card_html("ğŸ‘µ é«˜ç ‚ (å®Ÿå®¶)", taka_val, taka_theme),
            unsafe_allow_html=True,
        )
    with c2:
        st.markdown(
            render_status_card_html("ğŸ  ä¼Šä¸¹ (è‡ªå®…)", itami_val, itami_theme),
            unsafe_allow_html=True,
        )
    with c3:
        st.markdown(
            render_status_card_html("ğŸš— è»Š (ä¼Šä¸¹)", car_val, car_theme),
            unsafe_allow_html=True,
        )

    c4, c5, c6 = st.columns(3)
    with c4:
        st.markdown(
            render_status_card_html("ğŸš ç‚Šé£¯å™¨", rice_val, rice_theme),
            unsafe_allow_html=True,
        )
    with c5:
        st.markdown(
            render_status_card_html("ğŸ’° ä»Šæœˆã®é›»æ°—ä»£", elec_val, "theme-blue"),
            unsafe_allow_html=True,
        )
    with c6:
        st.markdown(
            render_status_card_html("ğŸš² é§è¼ªå ´å¾…æ©Ÿ", bicycle_val, bicycle_theme),
            unsafe_allow_html=True,
        )

    c7, c8, c9 = st.columns(3)
    with c7:
        st.markdown(
            render_status_card_html("ğŸšƒ JRé‹è¡Œæƒ…å ±", traffic_val, traffic_theme),
            unsafe_allow_html=True,
        )
    with c8:
        st.markdown(
            render_status_card_html("ğŸ–¥ï¸ ã‚µãƒ¼ãƒãƒ¼", server_val, server_theme),
            unsafe_allow_html=True,
        )
    with c9:
        st.markdown(
            render_status_card_html("ğŸ—„ï¸ NAS", nas_val, nas_theme),
            unsafe_allow_html=True,
        )

    st.markdown("---")


def render_traffic_tab():
    """äº¤é€šæƒ…å ±ã‚¿ãƒ–ã®æç”»"""
    st.subheader("ğŸšƒ JRå®å¡šç·šãƒ»ç¥æˆ¸ç·š é‹è¡ŒçŠ¶æ³")
    _, _, line_g, line_a = get_traffic_status()

    c_t1, c_t2 = st.columns(2)

    for col, line, name in [(c_t1, line_g, "JR å®å¡šç·š"), (c_t2, line_a, "JR ç¥æˆ¸ç·š")]:
        bg_color = "#ffebee" if line["is_delay"] else "#e8f5e9"
        status_color = "#d32f2f" if line["is_delay"] else "#2e7d32"
        with col:
            st.markdown(
                f"""
            <div style="background-color:{bg_color}; padding:15px; border-radius:10px; border:1px solid #ccc;">
                <h3 style="margin:0; color:#333;">{name}</h3>
                <h2 style="margin:5px 0; color:{status_color};">{line['status']}</h2>
                <p style="margin:0;">{line['detail']}</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

    st.markdown("---")
    now_jst = datetime.now(pytz.timezone("Asia/Tokyo"))
    current_hour = now_jst.hour
    dep_time = (now_jst + timedelta(minutes=20)).strftime("%H:%M")

    st.subheader(f"ğŸ“ ãƒ«ãƒ¼ãƒˆæ¤œç´¢ ({dep_time} å‡ºç™ºæƒ³å®š)")
    container = st.container()

    if 4 <= current_hour < 12:
        _render_route_search(container, "ä¼Šä¸¹(å…µåº«çœŒ)", "é•·å²¡äº¬", "ğŸ“¤ å‡ºå‹¤ãƒ«ãƒ¼ãƒˆ")
    elif 12 <= current_hour <= 23:
        _render_route_search(container, "é•·å²¡äº¬", "ä¼Šä¸¹(å…µåº«çœŒ)", "ğŸ“¥ å¸°å®…ãƒ«ãƒ¼ãƒˆ")
    else:
        st.caption("â€»æ·±å¤œå¸¯ã®ãŸã‚å¸°å®…ãƒ«ãƒ¼ãƒˆã‚’è¡¨ç¤ºã—ã¾ã™")
        _render_route_search(container, "é•·å²¡äº¬", "ä¼Šä¸¹(å…µåº«çœŒ)", "ğŸ“¥ å¸°å®…ãƒ«ãƒ¼ãƒˆ")


def _render_route_search(col, from_st: str, to_st: str, label_icon: str):
    with col:
        st.markdown(f"##### {label_icon} {from_st} â†’ {to_st}")
        data = train_service.get_route_info(from_st, to_st)

        if data["summary"] == "å–å¾—æˆåŠŸ":
            details_html = ""
            if data.get("details"):
                steps = []
                for d in data["details"]:
                    if "â¬‡ï¸" in d:
                        steps.append(f"<div class='line-node'>{d}</div>")
                    elif "ğŸ”„" in d:
                        steps.append(f"<div class='transfer-mark'>{d}</div>")
                    else:
                        steps.append(f"<div class='station-node'>{d}</div>")
                details_html = f"<div class='route-path'>{''.join(steps)}</div>"

            st.markdown(
                f"""
            <div class="route-card">
                <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:10px;">
                    <span style="font-size:1.3rem; font-weight:bold; color:#0d47a1;">{data['departure']}</span>
                    <span style="color:#777;">â¡</span>
                    <span style="font-size:1.3rem; font-weight:bold; color:#0d47a1;">{data['arrival']}</span>
                </div>
                <div style="display:flex; justify-content:space-between; color:#555; margin-bottom:5px;">
                    <span>â±ï¸ <b>{data['duration']}</b></span>
                    <span>ğŸ’° {data['cost']}</span>
                </div>
                <div style="font-size:0.9rem; color:#666;">
                    <span>ğŸ”„ ä¹—æ›: {data['transfer']}</span>
                </div>
                {details_html}
            </div>
            """,
                unsafe_allow_html=True,
            )
            if data["url"]:
                st.link_button(f"ğŸ”— Yahoo!è·¯ç·šæƒ…å ±ã§è¦‹ã‚‹", data["url"])
        else:
            st.warning("ãƒ«ãƒ¼ãƒˆæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")


def render_photos_tab(df_security_log: pd.DataFrame):
    """å†™çœŸãƒ»é˜²çŠ¯ã‚¿ãƒ–"""
    st.subheader("ğŸ–¼ï¸ ã‚«ãƒ¡ãƒ©ãƒ»ã‚®ãƒ£ãƒ©ãƒªãƒ¼")
    img_dir = os.path.join(config.ASSETS_DIR, "snapshots")
    images = sorted(glob.glob(os.path.join(img_dir, "*.jpg")), reverse=True)
    if images:
        cols_img = st.columns(4)
        for i, p in enumerate(images[:4]):
            cols_img[i].image(p, caption=os.path.basename(p), width="stretch")
        with st.expander("ğŸ“‚ éå»ã®å†™çœŸ"):
            cols_past = st.columns(4)
            for i, p in enumerate(images[4:20]):
                cols_past[i % 4].image(
                    p, caption=os.path.basename(p), width="stretch"
                )
    else:
        st.info("å†™çœŸãªã—")

    st.subheader("ğŸ›¡ï¸ é˜²çŠ¯ãƒ­ã‚° (æ¤œçŸ¥åˆ†é¡)")
    if not df_security_log.empty:
        df_security_log = apply_friendly_names(df_security_log)
        cols = ["timestamp", "friendly_name"]
        if "classification" in df_security_log.columns:
            cols.append("classification")
        if "image_path" in df_security_log.columns:
            cols.append("image_path")
        df_disp = df_security_log[cols].copy()
        df_disp.columns = [
            c.replace("timestamp", "æ¤œçŸ¥æ™‚åˆ»")
            .replace("friendly_name", "ãƒ‡ãƒã‚¤ã‚¹")
            .replace("classification", "æ¤œçŸ¥ç¨®åˆ¥")
            .replace("image_path", "ç”»åƒ")
            for c in df_disp.columns
        ]
        st.dataframe(df_disp, width="stretch")
    else:
        st.info("ä¸å¯©ãªæ¤œçŸ¥ã¯ã‚ã‚Šã¾ã›ã‚“")


def render_electricity_tab(df_sensor: pd.DataFrame, now: datetime):
    """é›»æ°—ãƒ»å®¶é›»ã‚¿ãƒ–"""
    if df_sensor.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    col_left, col_right = st.columns([1, 1])
    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    today_end = today_start + timedelta(days=1)
    yesterday_start = today_start - timedelta(days=1)

    with col_left:
        st.subheader("âš¡ æ¶ˆè²»é›»åŠ› (ä»Šæ—¥ vs æ˜¨æ—¥)")
        df_today = df_sensor[
            (df_sensor["device_type"] == "Nature Remo E Lite")
            & (df_sensor["timestamp"] >= today_start)
            & (df_sensor["timestamp"] < today_end)
        ].copy()
        df_yesterday = df_sensor[
            (df_sensor["device_type"] == "Nature Remo E Lite")
            & (df_sensor["timestamp"] >= yesterday_start)
            & (df_sensor["timestamp"] < today_start)
        ].copy()

        if not df_today.empty or not df_yesterday.empty:
            fig = go.Figure()
            if not df_yesterday.empty:
                df_yesterday["plot_time"] = df_yesterday["timestamp"] + timedelta(days=1)
                fig.add_trace(
                    go.Scatter(
                        x=df_yesterday["plot_time"],
                        y=df_yesterday["power_watts"],
                        mode="lines",
                        name="æ˜¨æ—¥",
                        line=dict(color="#cccccc", width=2),
                    )
                )
            if not df_today.empty:
                fig.add_trace(
                    go.Scatter(
                        x=df_today["timestamp"],
                        y=df_today["power_watts"],
                        mode="lines",
                        name="ä»Šæ—¥",
                        line=dict(color="#3366cc", width=3),
                    )
                )
            fig.update_layout(
                xaxis_range=[today_start, today_end],
                xaxis_title="æ™‚é–“",
                yaxis_title="é›»åŠ›(W)",
                legend=dict(
                    orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1
                ),
            )
            st.plotly_chart(fig, width="stretch")
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    with col_right:
        st.subheader("ğŸ”Œ å€‹åˆ¥å®¶é›» (ä»Šæ—¥)")
        df_app = df_sensor[
            (df_sensor["device_type"].str.contains("Plug", na=False))
            & (df_sensor["timestamp"] >= today_start)
            & (df_sensor["timestamp"] < today_end)
        ]
        if not df_app.empty:
            fig_app = px.line(
                df_app,
                x="timestamp",
                y="power_watts",
                color="friendly_name",
                title="ãƒ—ãƒ©ã‚°è¨ˆæ¸¬å€¤",
            )
            fig_app.update_xaxes(range=[today_start, today_end])
            st.plotly_chart(fig_app, width="stretch")
        else:
            st.info("ãƒ—ãƒ©ã‚°ãƒ‡ãƒ¼ã‚¿ãªã—")


def render_temperature_tab(df_sensor: pd.DataFrame, now: datetime):
    if df_sensor.empty or "device_type" not in df_sensor.columns:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ä»Šæ—¥ã®æ¨ç§»
    st.subheader("ğŸŒ¡ï¸ å®¤æ¸©ãƒ»æ¹¿åº¦ (ä»Šæ—¥ã®æ¨ç§»)")
    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    today_end = today_start + timedelta(days=1)
    df_temp = df_sensor[
        (df_sensor["device_type"].str.contains("Meter", na=False))
        & (df_sensor["timestamp"] >= today_start)
        & (df_sensor["timestamp"] < today_end)
    ]

    col1, col2 = st.columns(2)
    with col1:
        if not df_temp.empty:
            fig_t = px.line(
                df_temp,
                x="timestamp",
                y="temperature_celsius",
                color="friendly_name",
                title="å®¤æ¸© (â„ƒ)",
            )
            fig_t.update_xaxes(range=[today_start, today_end])
            st.plotly_chart(fig_t, width="stretch")
        else:
            st.info("ä»Šæ—¥ã®å®¤æ¸©ãƒ‡ãƒ¼ã‚¿ãªã—")

    with col2:
        if not df_temp.empty:
            fig_h = px.line(
                df_temp,
                x="timestamp",
                y="humidity_percent",
                color="friendly_name",
                title="æ¹¿åº¦ (%)",
            )
            fig_h.update_xaxes(range=[today_start, today_end])
            st.plotly_chart(fig_h, width="stretch")
        else:
            st.info("ä»Šæ—¥ã®æ¹¿åº¦ãƒ‡ãƒ¼ã‚¿ãªã—")

    st.markdown("---")

    # å¹´é–“æ¨ç§»ã‚°ãƒ©ãƒ•
    st.subheader(f"ğŸ“… å¹´é–“æ°—æ¸©ãƒ»å®¤æ¸©æ¨ç§» ({now.year}å¹´)")
    df_yearly = load_yearly_temperature_stats(now.year)

    if not df_yearly.empty:
        fig = go.Figure()

        if "out_max" in df_yearly.columns:
            fig.add_trace(
                go.Scatter(
                    x=df_yearly["date"],
                    y=df_yearly["out_max"],
                    mode="lines",
                    name="æœ€é«˜æ°—æ¸©(å¤–)",
                    line=dict(color="#ff5252", width=2),
                )
            )

        if "out_min" in df_yearly.columns:
            fig.add_trace(
                go.Scatter(
                    x=df_yearly["date"],
                    y=df_yearly["out_min"],
                    mode="lines",
                    name="æœ€ä½æ°—æ¸©(å¤–)",
                    line=dict(color="#448aff", width=2),
                )
            )

        if "in_max" in df_yearly.columns:
            fig.add_trace(
                go.Scatter(
                    x=df_yearly["date"],
                    y=df_yearly["in_max"],
                    mode="lines",
                    name="æœ€é«˜å®¤æ¸©(å†…)",
                    line=dict(color="#ff9800", width=2, dash="dot"),
                )
            )

        if "in_min" in df_yearly.columns:
            fig.add_trace(
                go.Scatter(
                    x=df_yearly["date"],
                    y=df_yearly["in_min"],
                    mode="lines",
                    name="æœ€ä½å®¤æ¸©(å†…)",
                    line=dict(color="#00bcd4", width=2, dash="dot"),
                )
            )

        fig.update_layout(
            xaxis_title="æ—¥ä»˜",
            yaxis_title="æ¸©åº¦(â„ƒ)",
            legend=dict(
                orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1
            ),
            hovermode="x unified",
        )
        st.plotly_chart(fig, width="stretch")
    else:
        st.info("å¹´é–“ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")


def render_health_tab(
    df_child: pd.DataFrame, df_poop: pd.DataFrame, df_food: pd.DataFrame
):
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("##### ğŸ¥ å­ä¾›")
        if not df_child.empty:
            st.dataframe(
                df_child[["timestamp", "child_name", "condition"]],
                width="stretch",
            )
    with c2:
        st.markdown("##### ğŸ’© æ’ä¾¿")
        if not df_poop.empty:
            st.dataframe(
                df_poop[["timestamp", "user_name", "condition"]],
                width="stretch",
            )
    st.markdown("##### ğŸ½ï¸ é£Ÿäº‹")
    if not df_food.empty:
        st.dataframe(
            df_food[["timestamp", "menu_category"]], width="stretch"
        )


def render_takasago_tab(df_sensor: pd.DataFrame):
    """é«˜ç ‚è©³ç´°ã‚¿ãƒ–"""
    if not df_sensor.empty:
        st.subheader("ğŸ‘µ å®Ÿå®¶ãƒ­ã‚°")
        st.dataframe(
            df_sensor[df_sensor["location"] == "é«˜ç ‚"][
                ["timestamp", "friendly_name", "contact_state"]
            ].head(50),
            width="stretch",
        )


def render_logs_tab(df_sensor: pd.DataFrame):
    """å…¨ãƒ­ã‚°ã‚¿ãƒ–"""
    if not df_sensor.empty:
        locs = df_sensor["location"].unique()
        sel = st.multiselect("å ´æ‰€", locs, default=locs)
        st.dataframe(
            df_sensor[df_sensor["location"].isin(sel)][
                ["timestamp", "friendly_name", "location", "contact_state", "power_watts"]
            ].head(200),
            width="stretch",
        )


def render_trends_tab():
    """æœ€è¿‘ã®æµè¡Œã‚¿ãƒ–"""
    st.title("ğŸŒŸ æœ€è¿‘ã®æµè¡Œãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰æ¨ç§»")
    st.caption("Google Playã‚¹ãƒˆã‚¢ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæœ€æ–°3å›åˆ†ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™")

    dates = load_ranking_dates(limit=3)
    if not dates:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    def render_history_section(title, ranking_type):
        st.subheader(title)
        cols = st.columns(len(dates))
        for i, date_str in enumerate(dates):
            with cols[i]:
                label = "ä»Šé€±" if i == 0 else ("å…ˆé€±" if i == 1 else "å…ˆã€…é€±")
                st.markdown(f"**{label} ({date_str[5:]})**")
                df = load_ranking_data(date_str, ranking_type)
                if df.empty:
                    st.write("- ãƒ‡ãƒ¼ã‚¿ãªã— -")
                    continue
                for _, row in df.iterrows():
                    url = f"https://play.google.com/store/apps/details?id={row['app_id']}"
                    st.markdown(f"{row['rank']}. [{row['title']}]({url})")

    render_history_section("ğŸ†“ ç„¡æ–™ãƒˆãƒƒãƒ— (æµè¡Œ)", "free")
    st.markdown("---")
    render_history_section("ğŸ’° å£²ä¸Šãƒˆãƒƒãƒ— (äººæ°—)", "grossing")


def render_bicycle_tab(df_bicycle: pd.DataFrame):
    """é§è¼ªå ´ã‚¿ãƒ–ã®æç”»"""
    st.title("ğŸš² é§è¼ªå ´å¾…æ©Ÿæ•°æ¨ç§»")

    if df_bicycle.empty:
        st.info("é§è¼ªå ´ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    target_areas = [
        "JRä¼Šä¸¹é§…å‰(ç¬¬1)è‡ªè»¢è»Šé§è»Šå ´ (A)",
        "JRä¼Šä¸¹é§…å‰(ç¬¬3)è‡ªè»¢è»Šé§è»Šå ´ (A)",
        "JRä¼Šä¸¹é§…å‰(ç¬¬3)è‡ªè»¢è»Šé§è»Šå ´ (E)",
    ]

    df_target = df_bicycle[df_bicycle["area_name"].isin(target_areas)].copy()

    if df_target.empty:
        st.warning("æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒªã‚¢ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        with st.expander("ç¾åœ¨å–å¾—ã§ãã¦ã„ã‚‹ã‚¨ãƒªã‚¢ä¸€è¦§"):
            st.write(df_bicycle["area_name"].unique())
        return

    fig = px.line(
        df_target,
        x="timestamp",
        y="waiting_count",
        color="area_name",
        title="å¾…æ©Ÿäººæ•°ã®å¤‰åŒ–",
        markers=True,
        symbol="area_name",
    )
    fig.update_layout(
        xaxis_title="æ—¥æ™‚",
        yaxis_title="å¾…æ©Ÿæ•° (äºº/å°)",
        legend=dict(
            orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1
        ),
    )
    st.plotly_chart(fig, width="stretch")

    st.subheader("ğŸ“Š æœ€æ–°ã®çŠ¶æ³")
    latest_df = df_target.sort_values(
        "timestamp", ascending=False
    ).drop_duplicates("area_name")
    st.dataframe(
        latest_df[
            ["timestamp", "area_name", "waiting_count", "status_text"]
        ].sort_values("area_name"),
        width="stretch",
    )


def render_quest_tab():
    """Family Questã®çŠ¶æ³ã‚’è¡¨ç¤ºã™ã‚‹ã‚¿ãƒ–"""
    st.title("âš”ï¸ Family Quest ç¾åœ¨ã®çŠ¶æ³")
    
    try:
        with common.get_db_cursor() as cur:
            cur.execute("SELECT name, exp, gold, job_class FROM quest_users ORDER BY exp DESC")
            rows = cur.fetchall()
            
            cur.execute("""
                SELECT u.name, h.quest_title, h.completed_at 
                FROM quest_history h
                JOIN quest_users u ON h.user_id = u.user_id
                ORDER BY h.completed_at DESC 
                LIMIT 5
            """)
            history = cur.fetchall()

        if not rows:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ seed_quest_data.py ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ã‚¢ãƒ—ãƒªã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™»éŒ²ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
            return

        cols = st.columns(len(rows))
        for i, (name, exp, gold, job_class) in enumerate(rows):
            with cols[i]:
                rank_icon = "ğŸ‘‘" if i == 0 else "ğŸ›¡ï¸"
                st.metric(
                    label=f"{rank_icon} {name} ({job_class})",
                    value=f"{exp} EXP",
                    delta=f"{gold} G"
                )

        st.divider()

        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“Š çµŒé¨“å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            df_quest = pd.DataFrame(rows, columns=["åå‰", "çµŒé¨“å€¤", "ã‚´ãƒ¼ãƒ«ãƒ‰", "è·æ¥­"])
            fig = px.bar(
                df_quest, 
                x="åå‰", 
                y="çµŒé¨“å€¤", 
                color="è·æ¥­", 
                text="çµŒé¨“å€¤",
                title="ç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«çŠ¶æ³"
            )
            fig.update_traces(textposition='outside')
            st.plotly_chart(fig, width="stretch")

        with col2:
            st.subheader("ğŸ“œ æœ€è¿‘ã®é”æˆå±¥æ­´")
            if history:
                for name, title, completed_at in history:
                    try:
                        t_str = completed_at.split('.')[0].replace('T', ' ')
                        dt = datetime.strptime(t_str, '%Y-%m-%d %H:%M:%S')
                        time_display = dt.strftime('%m/%d %H:%M')
                    except:
                        time_display = completed_at

                    st.markdown(f"**{name}** ãŒ **ã€{title}ã€** ã‚’é”æˆï¼  \n<span style='color:grey; font-size:0.8em'>({time_display})</span>", unsafe_allow_html=True)
                    st.write("---")
            else:
                st.write("ã¾ã å†’é™ºã®è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“")

    except Exception as e:
        st.error(f"ã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logger.error(f"Quest Tab Error: {e}")


def render_system_tab():
    """ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã‚¿ãƒ–ã®æç”»"""
    st.title("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")

    st.subheader("ğŸŒ å¤–éƒ¨æ¥ç¶š (ngrok)")
    urls = get_ngrok_url()

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ğŸ“± LINE Bot / Server (Port 8000)**")
        if urls.get("server"):
            st.success(f"æ¥ç¶šOK: {urls['server']}")
            st.caption("â€»LINE Botã®è¨­å®šURLã¯ã“ã‚Œã«ãªã‚Šã¾ã™")
        else:
            st.error("å–å¾—å¤±æ•— (ngrokã‚’ç¢ºèªã—ã¦ãã ã•ã„)")

    with c2:
        st.markdown("**ğŸ“Š Dashboard (Port 8501)**")
        if urls.get("dashboard"):
            st.success(f"æ¥ç¶šOK: {urls['dashboard']}")
            st.link_button("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’é–‹ã", urls['dashboard'])
        else:
            st.warning("å–å¾—å¤±æ•— (å›ºå®šãƒ‰ãƒ¡ã‚¤ãƒ³è¨­å®šã‚’ç¢ºèª)")

    st.markdown("---")

    st.subheader("ğŸ’» ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ³")

    disk = get_disk_usage()
    if disk:
        st.write(
            f"**ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {disk['percent']:.1f}%** (ä½¿ç”¨ {disk['used_gb']} GB / å…¨ä½“ {disk['total_gb']} GB)"
        )
        st.progress(int(disk["percent"]))

    st.write("")

    mem = get_memory_usage()
    if mem:
        st.write(
            f"**ğŸ§  ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {mem['percent']:.1f}%** (ä½¿ç”¨ {mem['used_mb']} MB / å…¨ä½“ {mem['total_mb']} MB)"
        )
        st.caption(f"å®Ÿè³ªç©ºãå®¹é‡ (Available): {mem['available_mb']} MB")
        st.progress(int(mem["percent"]))
    else:
        st.warning("ãƒ¡ãƒ¢ãƒªæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")

    st.markdown("---")

    st.subheader("ğŸ—„ï¸ NAS çŠ¶æ…‹ (BUFFALO LS720D)")
    nas_data = load_nas_status()

    if nas_data is not None:
        c_nas1, c_nas2, c_nas3 = st.columns(3)
        with c_nas1:
            ping_icon = "âœ…" if nas_data["status_ping"] == "OK" else "âŒ"
            st.metric("Pingç–é€š", f"{ping_icon} {nas_data['status_ping']}")
        with c_nas2:
            mount_icon = "âœ…" if nas_data["status_mount"] == "OK" else "âŒ"
            st.metric("ãƒã‚¦ãƒ³ãƒˆ", f"{mount_icon} {nas_data['status_mount']}")
        with c_nas3:
            ts = nas_data["timestamp"]
            if isinstance(ts, str):
                if "T" in ts:
                    ts = pd.to_datetime(ts).tz_localize("UTC").tz_convert("Asia/Tokyo")
                else:
                    ts = pd.to_datetime(ts)
            last_upd = ts.strftime("%m/%d %H:%M")
            st.metric("æœ€çµ‚ç¢ºèª", last_upd)

        if nas_data["total_gb"] > 0:
            usage_rate = nas_data["percent"]
            st.write(
                f"**ğŸ’¾ NASãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {usage_rate:.1f}%** (ä½¿ç”¨ {nas_data['used_gb']} GB / å…¨ä½“ {nas_data['total_gb']} GB)"
            )
            if usage_rate > 90:
                st.warning("âš ï¸ å®¹é‡ãŒæ®‹ã‚Šå°‘ãªããªã£ã¦ã„ã¾ã™ï¼")
            st.progress(int(usage_rate))
        else:
            st.warning("å®¹é‡ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¦ã„ã¾ã›ã‚“")
    else:
        st.info("NASã®ç›£è¦–ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“")

    st.markdown("---")

    st.subheader("ğŸ“œ ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚° (Journalctl)")

    search_mode = st.radio("æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰", ["ç›´è¿‘ã®ãƒ­ã‚°ã‚’è¡¨ç¤º", "æ—¥ä»˜ã‚’æŒ‡å®šã—ã¦æ¤œç´¢"], horizontal=True)
    col_opt1, col_opt2, _ = st.columns([1, 1, 2])
    target_date = None
    lines_val = 50

    with col_opt1:
        if search_mode == "æ—¥ä»˜ã‚’æŒ‡å®šã—ã¦æ¤œç´¢":
            target_date = st.date_input("å¯¾è±¡æ—¥", date.today())
        else:
            lines_val = st.selectbox("è¡¨ç¤ºè¡Œæ•°", [50, 100, 200, 500], index=0)

    with col_opt2:
        level_options = {
            "å…¨ã¦ (Infoä»¥ä¸Š)": None,
            "è­¦å‘Š (Warningä»¥ä¸Š)": "warning",
            "ã‚¨ãƒ©ãƒ¼ (Errorã®ã¿)": "err",
        }
        selected_label = st.selectbox("ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«", list(level_options.keys()))
        selected_priority = level_options[selected_label]

    if st.button("ğŸ”„ ãƒ­ã‚°ã‚’æ›´æ–°"):
        st.rerun()

    logs = get_system_logs(
        lines=lines_val, priority=selected_priority, target_date=target_date
    )

    if not logs:
        st.info("è©²å½“ã™ã‚‹ãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“")
    else:
        st.code(logs, language="text")

    st.markdown("---")
    st.subheader("âš ï¸ ã‚µãƒ¼ãƒãƒ¼æ“ä½œ")

    col_reboot, _ = st.columns([1, 2])
    with col_reboot:
        if st.button("ğŸ”„ ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹• (Restart Service)"):
            try:
                st.info("å†èµ·å‹•ã‚³ãƒãƒ³ãƒ‰ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
                subprocess.run(
                    ["sudo", "systemctl", "restart", "home_system"], check=True
                )
                st.success("å†èµ·å‹•ã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸã€‚10ç§’å¾Œã«ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            except subprocess.CalledProcessError as e:
                st.error(f"å†èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

    st.markdown("---")
    st.subheader("ğŸ“¦ ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")

    import glob

    backup_dir = os.path.join(config.BASE_DIR, "..", "backups")
    if os.path.exists(backup_dir):
        files = sorted(glob.glob(os.path.join(backup_dir, "*.zip")), reverse=True)
        if files:
            latest_file = files[0]
            f_name = os.path.basename(latest_file)
            f_size = os.path.getsize(latest_file) / (1024 * 1024)
            f_time = datetime.fromtimestamp(os.path.getmtime(latest_file)).strftime(
                "%Y/%m/%d %H:%M"
            )

            c_bk1, c_bk2 = st.columns([2, 1])
            with c_bk1:
                st.success(f"âœ… æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {f_time}")
                st.caption(f"ãƒ•ã‚¡ã‚¤ãƒ«å: {f_name} | ã‚µã‚¤ã‚º: {f_size:.2f} MB")
            with c_bk2:
                with open(latest_file, "rb") as f:
                    st.download_button(
                        "â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name=f_name, mime="application/zip"
                    )

            with st.expander("ğŸ—‚ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å±¥æ­´ (æœ€æ–°5ä»¶)"):
                for bf in files[:5]:
                    bs = os.path.getsize(bf) / (1024 * 1024)
                    bt = datetime.fromtimestamp(os.path.getmtime(bf)).strftime(
                        "%m/%d %H:%M"
                    )
                    st.text(f"ãƒ»{bt} : {os.path.basename(bf)} ({bs:.2f}MB)")
        else:
            st.warning("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“")
            if st.button("ä»Šã™ãæ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ"):
                import MY_HOME_SYSTEM.backup_service as backup_service

                success, res, size = backup_service.perform_backup()
                if success:
                    st.success(f"å®Œäº†ã—ã¾ã—ãŸï¼ ({size:.1f}MB)")
                    st.rerun()
                else:
                    st.error(f"å¤±æ•—: {res}")
    else:
        st.info("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆæ¬¡å›å®Ÿè¡Œæ™‚ã«ä½œæˆã•ã‚Œã¾ã™ï¼‰")


# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===


def main():
    with st.sidebar:
        st.header("è¨­å®š")
        if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"):
            st.cache_data.clear()
            st.rerun()
        st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
        now = datetime.now(pytz.timezone("Asia/Tokyo"))
        logger.info(f"Dashboard Rendering... ({now.strftime('%H:%M:%S')})")

    try:
        st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
        now = datetime.now(pytz.timezone("Asia/Tokyo"))

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df_sensor = load_sensor_data(limit=10000)
        df_weather = load_weather_history(days=40, location="ä¼Šä¸¹")
        df_poop = load_generic_data(config.SQLITE_TABLE_DEFECATION)
        df_child = load_generic_data(config.SQLITE_TABLE_CHILD)
        df_food = load_generic_data(config.SQLITE_TABLE_FOOD)
        df_car = load_generic_data(config.SQLITE_TABLE_CAR)
        df_security_log = load_generic_data("security_logs", limit=100)
        df_bicycle = load_bicycle_data(limit=3000)
        nas_data = load_nas_status()

        # AIãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        report = load_ai_report()
        if report is not None:
            report_time = pd.to_datetime(report["timestamp"]).tz_convert("Asia/Tokyo")
            time_str = report_time.strftime("%H:%M")
            hour = report_time.hour
            icon = "â˜€ï¸" if 5 <= hour < 11 else ("ğŸ•›" if 11 <= hour < 17 else "ğŸŒ™")
            with st.expander(
                f"{icon} ã‚»ãƒã‚¹ãƒãƒ£ãƒ³ã‹ã‚‰ã®å ±å‘Š ({time_str}) - ã‚¿ãƒƒãƒ—ã—ã¦èª­ã‚€", expanded=False
            ):
                st.markdown(report["message"].replace("\n", "  \n"))

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚«ãƒ¼ãƒ‰ï¼‰è¡¨ç¤º
        render_dashboard_summary(now, df_sensor, df_car, df_bicycle, nas_data)

        # ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ
        tabs = st.tabs(
            [
                "âš”ï¸ ã‚¯ã‚¨ã‚¹ãƒˆ",  # <--- è¿½åŠ 
                "ğŸšƒ é›»è»Šé…å»¶",
                "ğŸ“¸ é˜²çŠ¯ã‚«ãƒ¡ãƒ©",
                "ğŸ’¡ é›»åŠ›ãƒ»ç’°å¢ƒ",
                "ğŸŒ¡ï¸ æ°—æ¸©è©³ç´°",
                "ğŸ¥ å¥åº·ç®¡ç†",
                "ğŸ‘µ é«˜ç ‚å®Ÿå®¶",
                "ğŸ“ ãƒ­ã‚°åˆ†æ",
                "ğŸ“Š ãƒˆãƒ¬ãƒ³ãƒ‰",
                "ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†",
                "ğŸš² é§è¼ªå ´",
            ]
        )

        (
            tab_quest,      # <--- è¿½åŠ 
            tab_train,
            tab_photo,
            tab_elec,
            tab_temp,
            tab_health,
            tab_taka,
            tab_log,
            tab_trends,
            tab_sys,
            tab_bicycle,
        ) = tabs

        with tab_quest:
            render_quest_tab()
        with tab_train:
            render_traffic_tab()
        with tab_photo:
            render_photos_tab(df_security_log)
        with tab_elec:
            render_electricity_tab(df_sensor, now)
        with tab_temp:
            render_temperature_tab(df_sensor, now)
        with tab_health:
            render_health_tab(df_child, df_poop, df_food)
        with tab_taka:
            render_takasago_tab(df_sensor)
        with tab_log:
            render_logs_tab(df_sensor)
        with tab_trends:
            render_trends_tab()
        with tab_sys:
            render_system_tab()
        with tab_bicycle:
            render_bicycle_tab(df_bicycle)

    except Exception as e:
        err_msg = f"ğŸ“‰ Dashboard Error: {e}"
        logger.error(err_msg)
        try:
            common.send_push(
                config.LINE_USER_ID,
                [{"type": "text", "text": err_msg}],
                target="discord",
                channel="error",
            )
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼é€ä¿¡è‡ªä½“ã®ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        st.error("ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(traceback.format_exc())


if __name__ == "__main__":
    main()