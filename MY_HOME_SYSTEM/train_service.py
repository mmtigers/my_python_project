# MY_HOME_SYSTEM/train_service.py
import requests
from bs4 import BeautifulSoup
import traceback
import re
from datetime import datetime, timedelta # è¿½åŠ 

# JRè¥¿æ—¥æœ¬ é‹è¡Œæƒ…å ±API
JR_WEST_JSON_URL = "https://www.train-guide.westjr.co.jp/api/v3/area_kinki_trafficinfo.json"

# Yahoo!è·¯ç·šæƒ…å ± ãƒ™ãƒ¼ã‚¹URL
YAHOO_SEARCH_URL = "https://transit.yahoo.co.jp/search/result"

def get_jr_traffic_status():
    """JRè¥¿æ—¥æœ¬ã®é‹è¡ŒçŠ¶æ³ã‚’å–å¾—"""
    results = {
        "å®å¡šç·š": {"status": "ğŸŸ¢ å¹³å¸¸é‹è»¢", "detail": "é…ã‚Œã¯ã‚ã‚Šã¾ã›ã‚“", "is_delay": False, "is_suspended": False},
        "ç¥æˆ¸ç·š": {"status": "ğŸŸ¢ å¹³å¸¸é‹è»¢", "detail": "é…ã‚Œã¯ã‚ã‚Šã¾ã›ã‚“", "is_delay": False, "is_suspended": False}
    }
    
    try:
        resp = requests.get(JR_WEST_JSON_URL, timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            if "lines" in data:
                for line_id, info in data["lines"].items():
                    target_name = ""
                    if line_id == "G": target_name = "å®å¡šç·š"
                    elif line_id == "A": target_name = "ç¥æˆ¸ç·š"
                    
                    if target_name:
                        status_text = info.get("status", "æƒ…å ±ã‚ã‚Š")
                        detail_text = info.get("text", "è©³ç´°æƒ…å ±ãªã—")
                        is_suspended = "è¦‹åˆ" in status_text or "é‹ä¼‘" in status_text
                        
                        results[target_name]["status"] = "ğŸ”´ " + status_text
                        results[target_name]["detail"] = detail_text
                        results[target_name]["is_delay"] = True
                        results[target_name]["is_suspended"] = is_suspended
    except Exception:
        pass 
        
    return results

def get_route_info(from_station="ä¼Šä¸¹(å…µåº«çœŒ)", to_station="é•·å²¡äº¬"):
    """
    Yahoo!è·¯ç·šæƒ…å ±ã‹ã‚‰æœ€çŸ­ãƒ«ãƒ¼ãƒˆã‚’å–å¾—
    â€»ç¾åœ¨æ™‚åˆ»ã®20åˆ†å¾Œã‚’å‡ºç™ºæ™‚åˆ»ã¨ã—ã¦æ¤œç´¢ã™ã‚‹
    """
    route_data = {
        "label": f"{from_station} â†’ {to_station}",
        "departure": "--:--",
        "arrival": "--:--",
        "duration": "--åˆ†",
        "transfer": "--å›",
        "cost": "----å††",
        "details": [],
        "url": "",
        "summary": "å–å¾—å¤±æ•—"
    }
    
    try:
        # ç¾åœ¨æ™‚åˆ» + 20åˆ† ã‚’è¨ˆç®—
        future_time = datetime.now() + timedelta(minutes=20)
        
        # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        params = {
            "from": from_station,
            "to": to_station,
            "y": future_time.year,
            "m": future_time.strftime("%m"),
            "d": future_time.strftime("%d"),
            "hh": future_time.hour,
            "m1": future_time.minute // 10,
            "m2": future_time.minute % 10,
            "type": "1", # 1:å‡ºç™ºæ™‚åˆ»æŒ‡å®š
            "s": "0"     # æ™‚é–“é †
        }
        
        resp = requests.get(YAHOO_SEARCH_URL, params=params, timeout=5)
        route_data["url"] = resp.url
        
        if resp.status_code != 200:
            return route_data
            
        soup = BeautifulSoup(resp.text, 'html.parser')
        route_elm = soup.select_one('#rsltlst li.el') or soup.select_one('.routeSummary')
        
        if route_elm:
            # 1. æ™‚é–“
            time_elm = route_elm.select_one('.time')
            if time_elm:
                time_text = time_elm.get_text(strip=True)
                times = re.findall(r'(\d{1,2}:\d{2})', time_text)
                if len(times) >= 2:
                    route_data["departure"] = times[0]
                    route_data["arrival"] = times[-1]

            # 2. æ‰€è¦æ™‚é–“
            dur_elm = route_elm.select_one('.time .small') or route_elm.select_one('.small')
            if dur_elm:
                route_data["duration"] = dur_elm.get_text(strip=True).replace("(", "").replace(")", "")

            # 3. é‹è³ƒãƒ»ä¹—æ›
            fare_elm = route_elm.select_one('.fare')
            if fare_elm: route_data["cost"] = fare_elm.get_text(strip=True)
            trans_elm = route_elm.select_one('.transfer')
            if trans_elm: route_data["transfer"] = trans_elm.get_text(strip=True)

            # 4. è©³ç´°ãƒ«ãƒ¼ãƒˆ
            detail_elm = soup.select_one('.routeDetail')
            if detail_elm:
                stations = [s.get_text(strip=True) for s in detail_elm.select('.station dt')]
                lines = [l.get_text(strip=True) for l in detail_elm.select('.transport div')]
                
                route_data["details"] = []
                if stations: 
                    route_data["details"].append(f"ğŸš‰ {stations[0]}")
                
                for i in range(len(lines)):
                    line_name = lines[i].replace("[train]", "").strip()
                    route_data["details"].append(f"â¬‡ï¸ {line_name}")
                    if i + 1 < len(stations):
                        station_name = stations[i+1]
                        if i + 1 == len(stations) - 1:
                            route_data["details"].append(f"ğŸ {station_name}")
                        else:
                            route_data["details"].append(f"ğŸ”„ {station_name}")

            route_data["summary"] = "å–å¾—æˆåŠŸ"
            
    except Exception as e:
        print(f"Route scrape error: {e}")
        route_data["summary"] = f"ã‚¨ãƒ©ãƒ¼: {str(e)}"
        
    return route_data